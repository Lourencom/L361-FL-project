{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Iacob-Alexandru-Andrei/flower.git@teaching\n",
      "  Cloning https://github.com/Iacob-Alexandru-Andrei/flower.git (to revision teaching) to /tmp/pip-req-build-dk0kx1vr\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Iacob-Alexandru-Andrei/flower.git /tmp/pip-req-build-dk0kx1vr\n",
      "  Running command git checkout -b teaching --track origin/teaching\n",
      "  Switched to a new branch 'teaching'\n",
      "  branch 'teaching' set up to track 'origin/teaching'.\n",
      "  Resolved https://github.com/Iacob-Alexandru-Andrei/flower.git to commit 1c4fcc1d4a6e8022ddf6f94ebedef1b8e70e0fc4\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: ray==2.6.3 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (2.6.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (8.1.8)\n",
      "Requirement already satisfied: filelock in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (3.17.0)\n",
      "Requirement already satisfied: jsonschema in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (24.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (6.0.2)\n",
      "Requirement already satisfied: aiosignal in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (1.5.0)\n",
      "Requirement already satisfied: requests in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (2.32.3)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (1.70.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from ray==2.6.3) (1.26.4)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=41.0.2 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from flwr==1.7.0) (41.0.7)\n",
      "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from flwr==1.7.0) (0.0.2)\n",
      "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from flwr==1.7.0) (3.21.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from cryptography<42.0.0,>=41.0.2->flwr==1.7.0) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from jsonschema->ray==2.6.3) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from jsonschema->ray==2.6.3) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from jsonschema->ray==2.6.3) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from jsonschema->ray==2.6.3) (0.22.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from requests->ray==2.6.3) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from requests->ray==2.6.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from requests->ray==2.6.3) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from requests->ray==2.6.3) (2025.1.31)\n",
      "Requirement already satisfied: pycparser in /home/lcm76/.conda/envs/fl-project/lib/python3.10/site-packages (from cffi>=1.12->cryptography<42.0.0,>=41.0.2->flwr==1.7.0) (2.22)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "# `pip` could produce some errors. Do not worry about them.\n",
    "# The execution has been verified; it's working anyway.\n",
    "! pip install --quiet --upgrade \"pip\"\n",
    "! pip install --quiet matplotlib tqdm seaborn\n",
    "! pip install git+https://github.com/Iacob-Alexandru-Andrei/flower.git@teaching \\\n",
    "    torch torchvision ray==\"2.6.3\"\n",
    "# The following is just needed to show the folder tree\n",
    "! apt-get install -qq tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from typing import Any\n",
    "from logging import INFO\n",
    "from collections import defaultdict, OrderedDict\n",
    "from collections.abc import Sequence, Callable\n",
    "import numbers\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from enum import IntEnum\n",
    "import flwr\n",
    "from flwr.server import History, ServerConfig\n",
    "from flwr.server.strategy import FedAvgM as FedAvg, Strategy\n",
    "from flwr.common import log, NDArrays, Scalar, Parameters, ndarrays_to_parameters\n",
    "from flwr.client.client import Client\n",
    "\n",
    "from common.client_utils import (\n",
    "    Net,\n",
    "    load_femnist_dataset,\n",
    "    get_network_generator_cnn as get_network_generator,\n",
    "    train_femnist,\n",
    "    test_femnist,\n",
    "    save_history,\n",
    "    aggregate_weighted_average\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add new seeds here for easy autocomplete\n",
    "class Seeds(IntEnum):\n",
    "    \"\"\"Seeds for reproducibility.\"\"\"\n",
    "\n",
    "    DEFAULT = 1337\n",
    "\n",
    "\n",
    "np.random.seed(Seeds.DEFAULT)\n",
    "random.seed(Seeds.DEFAULT)\n",
    "torch.manual_seed(Seeds.DEFAULT)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "PathType = Path | str | None\n",
    "\n",
    "from common.client_utils import get_device, set_model_parameters, get_model_parameters\n",
    "\n",
    "\n",
    "home_dir = Path.cwd()\n",
    "dataset_dir: Path = home_dir / \"femnist\"\n",
    "data_dir: Path = dataset_dir / \"data\"\n",
    "centralized_partition: Path = dataset_dir / \"client_data_mappings\" / \"centralized\"\n",
    "centralized_mapping: Path = dataset_dir / \"client_data_mappings\" / \"centralized\" / \"0\"\n",
    "federated_partition: Path = dataset_dir / \"client_data_mappings\" / \"fed_natural\"\n",
    "\n",
    "# Decompress dataset\n",
    "if not dataset_dir.exists():\n",
    "    with tarfile.open(home_dir / \"femnist.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(path=home_dir)\n",
    "    log(INFO, \"Dataset extracted in %s\", dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerRayClient(flwr.client.NumPyClient):\n",
    "    \"\"\"Flower client for the FEMNIST dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cid: int,\n",
    "        partition_dir: Path,\n",
    "        model_generator: Callable[[], Module],\n",
    "    ) -> None:\n",
    "        \"\"\"Init the client with its unique id and the folder to load data from.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            cid (int): Unique client id for a client used to map it to its data\n",
    "                partition\n",
    "            partition_dir (Path): The directory containing data for each\n",
    "                client/client id\n",
    "            model_generator (Callable[[], Module]): The model generator function\n",
    "        \"\"\"\n",
    "        self.cid = cid\n",
    "        log(INFO, \"cid: %s\", self.cid)\n",
    "        self.partition_dir = partition_dir\n",
    "        self.device = str(\n",
    "            torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        )\n",
    "        self.model_generator: Callable[[], Module] = model_generator\n",
    "        self.properties: dict[str, Scalar] = {\"tensor_type\": \"numpy.ndarray\"}\n",
    "\n",
    "    def set_parameters(self, parameters: NDArrays) -> Module:\n",
    "        \"\"\"Load weights inside the network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            parameters (NDArrays): set of weights to be loaded.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            [Module]: Network with new set of weights.\n",
    "        \"\"\"\n",
    "        net = self.model_generator()\n",
    "        return set_model_parameters(net, parameters)\n",
    "\n",
    "    def get_parameters(self, config: dict[str, Scalar]) -> NDArrays:\n",
    "        \"\"\"Return weights from a given model.\n",
    "\n",
    "        If no model is passed, then a local model is created.\n",
    "        This can be used to initialise a model in the\n",
    "        server.\n",
    "        The config param is not used but is mandatory in Flower.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            config (dict[int, Scalar]): dictionary containing configuration info.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            NDArrays: weights from the model.\n",
    "        \"\"\"\n",
    "        net = self.model_generator()\n",
    "        return get_model_parameters(net)\n",
    "\n",
    "    def fit(\n",
    "        self, parameters: NDArrays, config: dict[str, Scalar]\n",
    "    ) -> tuple[NDArrays, int, dict]:\n",
    "        \"\"\"Receive and train a model on the local client data.\n",
    "\n",
    "        It uses parameters from the config dict\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            net (NDArrays): Pytorch model parameters\n",
    "            config (dict[str, Scalar]): dictionary describing the training parameters\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            tuple[NDArrays, int, dict]: Returns the updated model, the size of the local\n",
    "                dataset and other metrics\n",
    "        \"\"\"\n",
    "        # Only create model right before training/testing\n",
    "        # To lower memory usage when idle\n",
    "        net = self.set_parameters(parameters)\n",
    "        net.to(self.device)\n",
    "\n",
    "        train_loader: DataLoader = self._create_data_loader(config, name=\"train\")\n",
    "        train_loss = self._train(net, train_loader=train_loader, config=config)\n",
    "        return get_model_parameters(net), len(train_loader), {\"train_loss\": train_loss}\n",
    "\n",
    "    def evaluate(\n",
    "        self, parameters: NDArrays, config: dict[str, Scalar]\n",
    "    ) -> tuple[float, int, dict]:\n",
    "        \"\"\"Receive and test a model on the local client data.\n",
    "\n",
    "        It uses parameters from the config dict\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            net (NDArrays): Pytorch model parameters\n",
    "            config (dict[str, Scalar]): dictionary describing the testing parameters\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            tuple[float, int, dict]: Returns the loss accumulate during testing, the\n",
    "                size of the local dataset and other metrics such as accuracy\n",
    "        \"\"\"\n",
    "        net = self.set_parameters(parameters)\n",
    "        net.to(self.device)\n",
    "\n",
    "        test_loader: DataLoader = self._create_data_loader(config, name=\"test\")\n",
    "        loss, accuracy = self._test(net, test_loader=test_loader, config=config)\n",
    "        return loss, len(test_loader), {\"local_accuracy\": accuracy}\n",
    "\n",
    "    def _create_data_loader(self, config: dict[str, Scalar], name: str) -> DataLoader:\n",
    "        \"\"\"Create the data loader using the specified config parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            config (dict[str, Scalar]): dictionary containing dataloader and dataset\n",
    "                parameters\n",
    "            mode (str): Load the training or testing set for the client\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            DataLoader: A pytorch dataloader iterable for training/testing\n",
    "        \"\"\"\n",
    "        batch_size = int(config[\"batch_size\"])\n",
    "        num_workers = int(config[\"num_workers\"])\n",
    "        dataset = self._load_dataset(name)\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=(name == \"train\"),\n",
    "        )\n",
    "\n",
    "    def _load_dataset(self, name: str) -> Dataset:\n",
    "        full_file: Path = self.partition_dir / str(self.cid)\n",
    "        return load_femnist_dataset(\n",
    "            mapping=full_file,\n",
    "            name=name,\n",
    "            data_dir=data_dir,\n",
    "        )\n",
    "\n",
    "    def _train(\n",
    "        self, net: Module, train_loader: DataLoader, config: dict[str, Scalar]\n",
    "    ) -> float:\n",
    "        return train_femnist(\n",
    "            net=net,\n",
    "            train_loader=train_loader,\n",
    "            epochs=int(config[\"epochs\"]),\n",
    "            device=self.device,\n",
    "            optimizer=torch.optim.AdamW(\n",
    "                net.parameters(),\n",
    "                lr=float(config[\"client_learning_rate\"]),\n",
    "                weight_decay=float(config[\"weight_decay\"]),\n",
    "            ),\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "            max_batches=int(config[\"max_batches\"]),\n",
    "        )\n",
    "\n",
    "    def _test(\n",
    "        self, net: Module, test_loader: DataLoader, config: dict[str, Scalar]\n",
    "    ) -> tuple[float, float]:\n",
    "        return test_femnist(\n",
    "            net=net,\n",
    "            test_loader=test_loader,\n",
    "            device=self.device,\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "            max_batches=int(config[\"max_batches\"]),\n",
    "        )\n",
    "\n",
    "    def get_properties(self, config: dict[str, Scalar]) -> dict[str, Scalar]:\n",
    "        \"\"\"Return properties for this client.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            config (dict[str, Scalar]): Options to be used for selecting specific\n",
    "            properties.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            dict[str, Scalar]: Returned properties.\n",
    "        \"\"\"\n",
    "        return self.properties\n",
    "\n",
    "    def get_train_set_size(self) -> int:\n",
    "        \"\"\"Return the client train set size.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            int: train set size of the client.\n",
    "        \"\"\"\n",
    "        return len(self._load_dataset(\"train\"))  # type: ignore[reportArgumentType]\n",
    "\n",
    "    def get_test_set_size(self) -> int:\n",
    "        \"\"\"Return the client test set size.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            int: test set size of the client.\n",
    "        \"\"\"\n",
    "        return len(self._load_dataset(\"test\"))  # type: ignore[reportArgumentType]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_client_seeded(\n",
    "    client: FlowerRayClient,\n",
    "    params: NDArrays,\n",
    "    conf: dict[str, Any],\n",
    "    seed: Seeds = Seeds.DEFAULT,\n",
    "    **kwargs: Any,\n",
    ") -> tuple[NDArrays, int, dict]:\n",
    "    \"\"\"Wrap to always seed client training.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    return client.fit(params, conf, **kwargs)\n",
    "\n",
    "def get_flower_client_generator(\n",
    "    model_generator: Callable[[], Module],\n",
    "    partition_dir: Path,\n",
    "    mapping_fn: Callable[[int], int] | None = None,\n",
    ") -> Callable[[str], FlowerRayClient]:\n",
    "    \"\"\"Wrap the client instance generator.\n",
    "\n",
    "    This provides the client generator with a model generator function.\n",
    "    Also, the partition directory must be passed.\n",
    "    A mapping function could be used for filtering/ordering clients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model_generator (Callable[[], Module]): model generator function.\n",
    "        partition_dir (Path): directory containing the partition.\n",
    "        mapping_fn (Optional[Callable[[int], int]]): function mapping sorted/filtered\n",
    "            ids to real cid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Callable[[str], FlowerRayClient]: client instance.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> FlowerRayClient:\n",
    "        \"\"\"Create a single client instance given the client id `cid`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            cid (str): client id, Flower requires this to be of type str.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            FlowerRayClient: client instance.\n",
    "        \"\"\"\n",
    "        return FlowerRayClient(\n",
    "            cid=mapping_fn(int(cid)) if mapping_fn is not None else int(cid),\n",
    "            partition_dir=partition_dir,\n",
    "            model_generator=model_generator,\n",
    "        )\n",
    "\n",
    "    return client_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_random_clients(\n",
    "    total_clients: int,\n",
    "    filter_less: int,\n",
    "    partition: Path,\n",
    "    seed: int | None = Seeds.DEFAULT,\n",
    ") -> Sequence[int]:\n",
    "    \"\"\"Sample randomly clients.\n",
    "\n",
    "    A filter on the client train set size is performed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        total_clients (int): total number of clients to sample.\n",
    "        filter_less (int): max number of train samples for which the client is\n",
    "            **discarded**.\n",
    "        partition (Path): path to the folder containing the partitioning.\n",
    "        seed (Optional[int], optional): seed for the random generator. Defaults to None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Sequence[int]: list of sample client ids as int.\n",
    "    \"\"\"\n",
    "    real_federated_cid_client_generator: Callable[[str], FlowerRayClient] = (\n",
    "        get_flower_client_generator(network_generator, federated_partition)\n",
    "    )\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    list_of_ids = []\n",
    "    while len(list_of_ids) < total_clients:\n",
    "        current_id = random.randint(0, 3229)\n",
    "        if (\n",
    "            real_federated_cid_client_generator(str(current_id)).get_train_set_size()\n",
    "            > filter_less\n",
    "        ):\n",
    "            list_of_ids.append(current_id)\n",
    "    return list_of_ids\n",
    "\n",
    "\n",
    "def get_federated_evaluation_function(\n",
    "    batch_size: int,\n",
    "    num_workers: int,\n",
    "    model_generator: Callable[[], Module],\n",
    "    criterion: Module,\n",
    "    max_batches: int,\n",
    ") -> Callable[[int, NDArrays, dict[str, Any]], tuple[float, dict[str, Scalar]]]:\n",
    "    \"\"\"Wrap the external federated evaluation function.\n",
    "\n",
    "    It provides the external federated evaluation function with some\n",
    "    parameters for the dataloader, the model generator function, and\n",
    "    the criterion used in the evaluation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        batch_size (int): batch size of the test set to use.\n",
    "        num_workers (int): correspond to `num_workers` param in the Dataloader object.\n",
    "        model_generator (Callable[[], Module]):  model generator function.\n",
    "        criterion (Module): PyTorch Module containing the criterion for evaluating the\n",
    "        model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Callable[[int, NDArrays, dict[str, Any]], tuple[float, dict[str, Scalar]]]:\n",
    "            external federated evaluation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def federated_evaluation_function(\n",
    "        server_round: int,\n",
    "        parameters: NDArrays,\n",
    "        fed_eval_config: dict[\n",
    "            str, Any\n",
    "        ],  # mandatory argument, even if it's not being used\n",
    "    ) -> tuple[float, dict[str, Scalar]]:\n",
    "        \"\"\"Evaluate federated model on the server.\n",
    "\n",
    "        It uses the centralized val set for sake of simplicity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            server_round (int): current federated round.\n",
    "            parameters (NDArrays): current model parameters.\n",
    "            fed_eval_config (dict[str, Any]): mandatory argument in Flower, can contain\n",
    "                some configuration info\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            tuple[float, dict[str, Scalar]]: evaluation results\n",
    "        \"\"\"\n",
    "        device: str = get_device()\n",
    "        net: Module = set_model_parameters(model_generator(), parameters)\n",
    "        net.to(device)\n",
    "\n",
    "        full_file: Path = centralized_mapping\n",
    "        dataset: Dataset = load_femnist_dataset(data_dir, full_file, \"val\")\n",
    "\n",
    "        valid_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        loss, acc = test_femnist(\n",
    "            net=net,\n",
    "            test_loader=valid_loader,\n",
    "            device=device,\n",
    "            criterion=criterion,\n",
    "            max_batches=max_batches,\n",
    "        )\n",
    "        return loss, {\"accuracy\": acc}\n",
    "\n",
    "    return federated_evaluation_function\n",
    "\n",
    "\n",
    "federated_evaluation_function = get_federated_evaluation_function(\n",
    "    batch_size=test_config[\"batch_size\"],\n",
    "    num_workers=test_config[\"num_workers\"],\n",
    "    model_generator=network_generator,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    max_batches=test_config[\"max_batches\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_seeded_simulation(\n",
    "    client_fn: Callable[[str], Client],\n",
    "    num_clients: int,\n",
    "    config: ServerConfig,\n",
    "    strategy: Strategy,\n",
    "    name: str,\n",
    "    return_all_parameters: bool = False,\n",
    "    seed: int = Seeds.DEFAULT,\n",
    "    iteration: int = 0,\n",
    ") -> tuple[list[tuple[int, NDArrays]], History]:\n",
    "    \"\"\"Wrap to seed client selection.\"\"\"\n",
    "    np.random.seed(seed ^ iteration)\n",
    "    torch.manual_seed(seed ^ iteration)\n",
    "    random.seed(seed ^ iteration)\n",
    "    parameter_list, hist = flwr.simulation.start_simulation_no_ray(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=num_clients,\n",
    "        client_resources={},\n",
    "        config=config,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "    save_history(home_dir, hist, name)\n",
    "    return parameter_list, hist\n",
    "\n",
    "\n",
    "\n",
    "def run_simulation(\n",
    "    # How long the FL process runs for:\n",
    "    num_rounds: int = num_rounds,\n",
    "    # Number of clients available\n",
    "    num_total_clients: int = num_total_clients,\n",
    "    # Number of clients used for train/eval\n",
    "    num_clients_per_round: int = num_clients_per_round,\n",
    "    num_evaluate_clients: int = num_evaluate_clients,\n",
    "    # If less clients are overall available stop FL\n",
    "    min_available_clients: int = num_total_clients,\n",
    "    # If less clients are available for fit/eval stop FL\n",
    "    min_fit_clients: int = num_clients_per_round,\n",
    "    min_evaluate_clients: int = num_evaluate_clients,\n",
    "    # Function to test the federated model performance\n",
    "    # external to a client instantiation\n",
    "    evaluate_fn: (\n",
    "        Callable[\n",
    "            [int, NDArrays, dict[str, Scalar]],\n",
    "            tuple[float, dict[str, Scalar]] | None,\n",
    "        ]\n",
    "        | None\n",
    "    ) = federated_evaluation_function,\n",
    "    # Functions to generate a config for client fit/evaluate\n",
    "    # by-default the same config is shallow-copied to all clients in Flower\n",
    "    # this version simply uses the configs defined above\n",
    "    on_fit_config_fn: Callable[\n",
    "        [int], dict[str, Scalar]\n",
    "    ] = lambda _x: federated_train_config,\n",
    "    on_evaluate_config_fn: Callable[[int], dict[str, Scalar]] = lambda _x: test_config,\n",
    "    # The \"Parameters\" type is merely a more packed version\n",
    "    # of numpy array lists, used internally by Flower\n",
    "    initial_parameters: Parameters = initial_parameters,\n",
    "    # If this is set to True, aggregation will work even if some clients fail\n",
    "    accept_failures: bool = False,\n",
    "    # How to combine the metrics dictionary returned by all clients for fit/eval\n",
    "    fit_metrics_aggregation_fn: Callable | None = aggregate_weighted_average,\n",
    "    evaluate_metrics_aggregation_fn: Callable | None = aggregate_weighted_average,\n",
    "    federated_client_generator: Callable[\n",
    "        [str], flwr.client.NumPyClient\n",
    "    ] = federated_client_generator,\n",
    "    # Aggregation learning rate for FedAvg\n",
    "    server_learning_rate: float = 1.0,\n",
    "    server_momentum: float = 0.0,\n",
    ") -> tuple[list[tuple[int, NDArrays]], History]:\n",
    "    \"\"\"Run a federated simulation using Flower.\"\"\"\n",
    "    log(INFO, \"FL will execute for %s rounds\", num_rounds)\n",
    "\n",
    "    # Percentage of clients used for train/eval\n",
    "    fraction_fit: float = float(num_clients_per_round) / num_total_clients\n",
    "    fraction_evaluate: float = float(num_evaluate_clients) / num_total_clients\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=fraction_fit,\n",
    "        fraction_evaluate=fraction_evaluate,\n",
    "        min_fit_clients=min_fit_clients,\n",
    "        min_evaluate_clients=min_evaluate_clients,\n",
    "        min_available_clients=min_available_clients,\n",
    "        on_fit_config_fn=on_fit_config_fn,\n",
    "        on_evaluate_config_fn=on_evaluate_config_fn,\n",
    "        evaluate_fn=evaluate_fn,\n",
    "        initial_parameters=initial_parameters,\n",
    "        accept_failures=accept_failures,\n",
    "        fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
    "        evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
    "        server_learning_rate=server_learning_rate,\n",
    "        server_momentum=server_momentum,\n",
    "    )\n",
    "    # resetting the seed for the random selection of clients\n",
    "    # this way the list of clients trained is guaranteed to be always the same\n",
    "\n",
    "    cfg = ServerConfig(num_rounds)\n",
    "\n",
    "    def simulator_client_generator(cid: str) -> Client:\n",
    "        return federated_client_generator(cid).to_client()\n",
    "\n",
    "    parameters_for_each_round, hist = start_seeded_simulation(\n",
    "        client_fn=simulator_client_generator,\n",
    "        num_clients=num_total_clients,\n",
    "        config=cfg,\n",
    "        strategy=strategy,\n",
    "        name=\"fedavg\",\n",
    "        return_all_parameters=True,\n",
    "        seed=Seeds.DEFAULT,\n",
    "    )\n",
    "    return parameters_for_each_round, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_generator = get_network_generator()\n",
    "seed_net: Net = network_generator()\n",
    "seed_model_params: NDArrays = get_model_parameters(seed_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-18 20:24:51,791 | 1323382480.py:21 | cid: 0\n",
      "INFO flwr 2025-02-18 20:24:59,232 | 1507471958.py:25 | Train Metrics = {'train_loss': 0.11736484438180923}\n",
      "  4%|▍         | 100/2329 [00:02<00:50, 44.56it/s]\n",
      "INFO flwr 2025-02-18 20:25:02,111 | 1507471958.py:31 | Loss = 369.5744831562042; Test Metrics = {'local_accuracy': 0.059375}\n"
     ]
    }
   ],
   "source": [
    "centralized_flower_client_generator: Callable[[str], FlowerRayClient] = (\n",
    "    get_flower_client_generator(network_generator, centralized_partition)\n",
    ")\n",
    "centralized_flower_client = centralized_flower_client_generator(str(0))\n",
    "\n",
    "centralized_train_config: dict[str, Any] = {\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "test_config: dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "# Train parameters on the centralised dataset\n",
    "trained_params, num_examples, train_metrics = fit_client_seeded(\n",
    "    centralized_flower_client, params=seed_model_params, conf=centralized_train_config\n",
    ")\n",
    "log(INFO, \"Train Metrics = %s\", train_metrics)\n",
    "\n",
    "# Test trained parameters on the centralised dataset\n",
    "loss, num_examples, test_metrics = centralized_flower_client.evaluate(\n",
    "    parameters=trained_params, config=test_config\n",
    ")\n",
    "log(INFO, \"Loss = %s; Test Metrics = %s\", loss, test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-18 20:25:02,124 | 1323382480.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-18 20:25:02,130 | 1323382480.py:21 | cid: 2184\n",
      "INFO flwr 2025-02-18 20:25:02,133 | 1323382480.py:21 | cid: 2907\n",
      "INFO flwr 2025-02-18 20:25:02,136 | 1323382480.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-18 20:25:02,139 | 1323382480.py:21 | cid: 2338\n",
      "INFO flwr 2025-02-18 20:25:02,142 | 1323382480.py:21 | cid: 2399\n",
      "INFO flwr 2025-02-18 20:25:02,144 | 1323382480.py:21 | cid: 2997\n",
      "INFO flwr 2025-02-18 20:25:02,148 | 1323382480.py:21 | cid: 678\n",
      "INFO flwr 2025-02-18 20:25:02,151 | 1323382480.py:21 | cid: 3175\n",
      "INFO flwr 2025-02-18 20:25:02,154 | 1323382480.py:21 | cid: 1363\n",
      "INFO flwr 2025-02-18 20:25:02,157 | 1323382480.py:21 | cid: 1571\n",
      "INFO flwr 2025-02-18 20:25:02,160 | 1323382480.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-18 20:25:02,164 | 1323382480.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-18 20:25:02,167 | 1323382480.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-18 20:25:02,171 | 1323382480.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-18 20:25:02,174 | 1323382480.py:21 | cid: 2855\n",
      "INFO flwr 2025-02-18 20:25:02,177 | 1323382480.py:21 | cid: 839\n",
      "INFO flwr 2025-02-18 20:25:02,180 | 1323382480.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-18 20:25:02,184 | 1323382480.py:21 | cid: 2688\n",
      "INFO flwr 2025-02-18 20:25:02,188 | 1323382480.py:21 | cid: 1494\n",
      "INFO flwr 2025-02-18 20:25:02,191 | 1323382480.py:21 | cid: 447\n",
      "INFO flwr 2025-02-18 20:25:02,195 | 1323382480.py:21 | cid: 1742\n",
      "INFO flwr 2025-02-18 20:25:02,199 | 1323382480.py:21 | cid: 2601\n",
      "INFO flwr 2025-02-18 20:25:02,202 | 1323382480.py:21 | cid: 1633\n",
      "INFO flwr 2025-02-18 20:25:02,205 | 1323382480.py:21 | cid: 267\n",
      "INFO flwr 2025-02-18 20:25:02,210 | 1323382480.py:21 | cid: 2070\n",
      "INFO flwr 2025-02-18 20:25:02,214 | 1323382480.py:21 | cid: 2863\n",
      "INFO flwr 2025-02-18 20:25:02,217 | 1323382480.py:21 | cid: 2736\n",
      "INFO flwr 2025-02-18 20:25:02,221 | 1323382480.py:21 | cid: 1425\n",
      "INFO flwr 2025-02-18 20:25:02,224 | 1323382480.py:21 | cid: 1653\n",
      "INFO flwr 2025-02-18 20:25:02,227 | 1323382480.py:21 | cid: 1652\n",
      "INFO flwr 2025-02-18 20:25:02,230 | 1323382480.py:21 | cid: 3020\n",
      "INFO flwr 2025-02-18 20:25:02,233 | 1323382480.py:21 | cid: 1273\n",
      "INFO flwr 2025-02-18 20:25:02,237 | 1323382480.py:21 | cid: 2718\n",
      "INFO flwr 2025-02-18 20:25:02,241 | 1323382480.py:21 | cid: 73\n",
      "INFO flwr 2025-02-18 20:25:02,246 | 1323382480.py:21 | cid: 1446\n",
      "INFO flwr 2025-02-18 20:25:02,249 | 1323382480.py:21 | cid: 2434\n",
      "INFO flwr 2025-02-18 20:25:02,253 | 1323382480.py:21 | cid: 485\n",
      "INFO flwr 2025-02-18 20:25:02,257 | 1323382480.py:21 | cid: 1887\n",
      "INFO flwr 2025-02-18 20:25:02,260 | 1323382480.py:21 | cid: 1009\n",
      "INFO flwr 2025-02-18 20:25:02,264 | 1323382480.py:21 | cid: 701\n",
      "INFO flwr 2025-02-18 20:25:02,269 | 1323382480.py:21 | cid: 1285\n",
      "INFO flwr 2025-02-18 20:25:02,274 | 1323382480.py:21 | cid: 2782\n",
      "INFO flwr 2025-02-18 20:25:02,277 | 1323382480.py:21 | cid: 2828\n",
      "INFO flwr 2025-02-18 20:25:02,280 | 1323382480.py:21 | cid: 2476\n",
      "INFO flwr 2025-02-18 20:25:02,283 | 1323382480.py:21 | cid: 1872\n",
      "INFO flwr 2025-02-18 20:25:02,286 | 1323382480.py:21 | cid: 2471\n",
      "INFO flwr 2025-02-18 20:25:02,289 | 1323382480.py:21 | cid: 1084\n",
      "INFO flwr 2025-02-18 20:25:02,294 | 1323382480.py:21 | cid: 823\n",
      "INFO flwr 2025-02-18 20:25:02,298 | 1323382480.py:21 | cid: 2243\n",
      "INFO flwr 2025-02-18 20:25:02,301 | 1323382480.py:21 | cid: 275\n",
      "INFO flwr 2025-02-18 20:25:02,305 | 1323382480.py:21 | cid: 2614\n",
      "INFO flwr 2025-02-18 20:25:02,308 | 1323382480.py:21 | cid: 2152\n",
      "INFO flwr 2025-02-18 20:25:02,311 | 1323382480.py:21 | cid: 2534\n",
      "INFO flwr 2025-02-18 20:25:02,315 | 1323382480.py:21 | cid: 2364\n",
      "INFO flwr 2025-02-18 20:25:02,318 | 1323382480.py:21 | cid: 3168\n",
      "INFO flwr 2025-02-18 20:25:02,321 | 1323382480.py:21 | cid: 179\n",
      "INFO flwr 2025-02-18 20:25:02,326 | 1323382480.py:21 | cid: 295\n",
      "INFO flwr 2025-02-18 20:25:02,330 | 1323382480.py:21 | cid: 1668\n",
      "INFO flwr 2025-02-18 20:25:02,333 | 1323382480.py:21 | cid: 2674\n",
      "INFO flwr 2025-02-18 20:25:02,336 | 1323382480.py:21 | cid: 2538\n",
      "INFO flwr 2025-02-18 20:25:02,339 | 1323382480.py:21 | cid: 220\n",
      "INFO flwr 2025-02-18 20:25:02,343 | 1323382480.py:21 | cid: 2767\n",
      "INFO flwr 2025-02-18 20:25:02,346 | 1323382480.py:21 | cid: 70\n",
      "INFO flwr 2025-02-18 20:25:02,351 | 1323382480.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-18 20:25:02,353 | 1323382480.py:21 | cid: 806\n",
      "INFO flwr 2025-02-18 20:25:02,357 | 1323382480.py:21 | cid: 807\n",
      "INFO flwr 2025-02-18 20:25:02,360 | 1323382480.py:21 | cid: 428\n",
      "INFO flwr 2025-02-18 20:25:02,365 | 1323382480.py:21 | cid: 1167\n",
      "INFO flwr 2025-02-18 20:25:02,368 | 1323382480.py:21 | cid: 805\n",
      "INFO flwr 2025-02-18 20:25:02,371 | 1323382480.py:21 | cid: 1852\n",
      "INFO flwr 2025-02-18 20:25:02,375 | 1323382480.py:21 | cid: 3068\n",
      "INFO flwr 2025-02-18 20:25:02,379 | 1323382480.py:21 | cid: 2329\n",
      "INFO flwr 2025-02-18 20:25:02,382 | 1323382480.py:21 | cid: 1287\n",
      "INFO flwr 2025-02-18 20:25:02,386 | 1323382480.py:21 | cid: 51\n",
      "INFO flwr 2025-02-18 20:25:02,391 | 1323382480.py:21 | cid: 2501\n",
      "INFO flwr 2025-02-18 20:25:02,394 | 1323382480.py:21 | cid: 1366\n",
      "INFO flwr 2025-02-18 20:25:02,397 | 1323382480.py:21 | cid: 1770\n",
      "INFO flwr 2025-02-18 20:25:02,399 | 1323382480.py:21 | cid: 2343\n",
      "INFO flwr 2025-02-18 20:25:02,402 | 1323382480.py:21 | cid: 937\n",
      "INFO flwr 2025-02-18 20:25:02,405 | 1323382480.py:21 | cid: 2251\n",
      "INFO flwr 2025-02-18 20:25:02,409 | 1323382480.py:21 | cid: 187\n",
      "INFO flwr 2025-02-18 20:25:02,413 | 1323382480.py:21 | cid: 3178\n",
      "INFO flwr 2025-02-18 20:25:02,416 | 1323382480.py:21 | cid: 2274\n",
      "INFO flwr 2025-02-18 20:25:02,419 | 1323382480.py:21 | cid: 2975\n",
      "INFO flwr 2025-02-18 20:25:02,422 | 1323382480.py:21 | cid: 2645\n",
      "INFO flwr 2025-02-18 20:25:02,425 | 1323382480.py:21 | cid: 1258\n",
      "INFO flwr 2025-02-18 20:25:02,429 | 1323382480.py:21 | cid: 875\n",
      "INFO flwr 2025-02-18 20:25:02,433 | 1323382480.py:21 | cid: 2504\n",
      "INFO flwr 2025-02-18 20:25:02,435 | 1323382480.py:21 | cid: 740\n",
      "INFO flwr 2025-02-18 20:25:02,438 | 1323382480.py:21 | cid: 2167\n",
      "INFO flwr 2025-02-18 20:25:02,441 | 1323382480.py:21 | cid: 2157\n",
      "INFO flwr 2025-02-18 20:25:02,444 | 1323382480.py:21 | cid: 2164\n",
      "INFO flwr 2025-02-18 20:25:02,447 | 1323382480.py:21 | cid: 757\n",
      "INFO flwr 2025-02-18 20:25:02,451 | 1323382480.py:21 | cid: 3175\n",
      "INFO flwr 2025-02-18 20:25:02,454 | 1323382480.py:21 | cid: 2714\n",
      "INFO flwr 2025-02-18 20:25:02,457 | 1323382480.py:21 | cid: 206\n",
      "INFO flwr 2025-02-18 20:25:02,461 | 1323382480.py:21 | cid: 3057\n",
      "INFO flwr 2025-02-18 20:25:02,464 | 1323382480.py:21 | cid: 2026\n",
      "INFO flwr 2025-02-18 20:25:02,467 | 1323382480.py:21 | cid: 2882\n",
      "INFO flwr 2025-02-18 20:25:02,471 | 1323382480.py:21 | cid: 3175\n",
      "INFO flwr 2025-02-18 20:25:02,541 | 1323382480.py:21 | cid: 51\n",
      "INFO flwr 2025-02-18 20:25:02,645 | 1323382480.py:21 | cid: 1668\n",
      "INFO flwr 2025-02-18 20:25:02,686 | 1323382480.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-18 20:25:02,765 | 985075976.py:39 | Metrics from trained models are: [[4, {'train_loss': 0.12444548681378365}], [11, {'train_loss': 0.12350443479689685}], [3, {'train_loss': 0.12324741234381993}], [4, {'train_loss': 0.12358860857784748}]]\n"
     ]
    }
   ],
   "source": [
    "total_clients: int = 100\n",
    "list_of_ids = sample_random_clients(\n",
    "    total_clients, centralized_train_config[\"batch_size\"], federated_partition\n",
    ")\n",
    "\n",
    "federated_client_generator: Callable[[str], FlowerRayClient] = (\n",
    "    get_flower_client_generator(\n",
    "        network_generator, federated_partition, lambda seq_id: list_of_ids[seq_id]\n",
    "    )\n",
    ")\n",
    "\n",
    "one_epoch_config: dict[str, Any] = {\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "test_config: dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "num_clients = 4\n",
    "clients = random.sample(list(range(total_clients)), num_clients)\n",
    "\n",
    "trained_models = [\n",
    "    fit_client_seeded(\n",
    "        federated_client_generator(str(cid)), seed_model_params, one_epoch_config\n",
    "    )\n",
    "    for cid in clients\n",
    "]\n",
    "\n",
    "trained_model_parameters = [model for model, *rest in trained_models]\n",
    "trained_model_metrics = [rest for _, *rest in trained_models]\n",
    "log(INFO, \"Metrics from trained models are: %s\", trained_model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-18 20:25:02,778 | 3762478787.py:72 | FL will execute for 10 rounds\n",
      "INFO flwr 2025-02-18 20:25:02,783 | app.py:149 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
      "INFO flwr 2025-02-18 20:25:02,784 | server_returns_parameters.py:81 | Initializing global parameters\n",
      "INFO flwr 2025-02-18 20:25:02,790 | server_returns_parameters.py:273 | Using initial parameters provided by strategy\n",
      "INFO flwr 2025-02-18 20:25:02,793 | server_returns_parameters.py:84 | Evaluating initial parameters\n",
      " 11%|█         | 100/891 [00:01<00:11, 66.25it/s]\n",
      "INFO flwr 2025-02-18 20:25:04,542 | server_returns_parameters.py:87 | initial parameters (loss, other metrics): 413.6843070983887, {'accuracy': 0.0065625}\n",
      "INFO flwr 2025-02-18 20:25:04,542 | server_returns_parameters.py:97 | FL starting\n",
      "DEBUG flwr 2025-02-18 20:25:04,543 | server_returns_parameters.py:223 | fit_round 1: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:04,544 | 1323382480.py:21 | cid: 1494\n",
      "INFO flwr 2025-02-18 20:25:04,547 | 1323382480.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-18 20:25:04,548 | 1323382480.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-18 20:25:04,551 | 1323382480.py:21 | cid: 2399\n",
      "INFO flwr 2025-02-18 20:25:04,555 | 1323382480.py:21 | cid: 1571\n",
      "DEBUG flwr 2025-02-18 20:25:05,842 | server_returns_parameters.py:237 | fit_round 1 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:02<00:18, 42.90it/s]\n",
      "INFO flwr 2025-02-18 20:25:08,404 | server_returns_parameters.py:120 | fit progress: (1, 364.48796558380127, {'accuracy': 0.074375}, 3.8608861359534785)\n",
      "INFO flwr 2025-02-18 20:25:08,405 | server_returns_parameters.py:171 | evaluate_round 1: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:08,406 | server_returns_parameters.py:223 | fit_round 2: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:08,407 | 1323382480.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-18 20:25:08,410 | 1323382480.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-18 20:25:08,414 | 1323382480.py:21 | cid: 1363\n",
      "INFO flwr 2025-02-18 20:25:08,417 | 1323382480.py:21 | cid: 1494\n",
      "INFO flwr 2025-02-18 20:25:08,421 | 1323382480.py:21 | cid: 2997\n",
      "DEBUG flwr 2025-02-18 20:25:10,684 | server_returns_parameters.py:237 | fit_round 2 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:14, 52.89it/s]\n",
      "INFO flwr 2025-02-18 20:25:12,808 | server_returns_parameters.py:120 | fit progress: (2, 342.5152292251587, {'accuracy': 0.079375}, 8.264621051959693)\n",
      "INFO flwr 2025-02-18 20:25:12,809 | server_returns_parameters.py:171 | evaluate_round 2: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:12,809 | server_returns_parameters.py:223 | fit_round 3: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:12,810 | 1323382480.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-18 20:25:12,813 | 1323382480.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-18 20:25:12,817 | 1323382480.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-18 20:25:12,821 | 1323382480.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-18 20:25:12,825 | 1323382480.py:21 | cid: 2907\n",
      "DEBUG flwr 2025-02-18 20:25:14,774 | server_returns_parameters.py:237 | fit_round 3 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:02<00:18, 41.96it/s]\n",
      "INFO flwr 2025-02-18 20:25:17,389 | server_returns_parameters.py:120 | fit progress: (3, 343.5453414916992, {'accuracy': 0.071875}, 12.845705816987902)\n",
      "INFO flwr 2025-02-18 20:25:17,390 | server_returns_parameters.py:171 | evaluate_round 3: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:17,391 | server_returns_parameters.py:223 | fit_round 4: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:17,392 | 1323382480.py:21 | cid: 839\n",
      "INFO flwr 2025-02-18 20:25:17,395 | 1323382480.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-18 20:25:17,397 | 1323382480.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-18 20:25:17,398 | 1323382480.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-18 20:25:17,402 | 1323382480.py:21 | cid: 1363\n",
      "DEBUG flwr 2025-02-18 20:25:19,173 | server_returns_parameters.py:237 | fit_round 4 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:10, 73.35it/s]\n",
      "INFO flwr 2025-02-18 20:25:20,766 | server_returns_parameters.py:120 | fit progress: (4, 347.0549645423889, {'accuracy': 0.078125}, 16.223380963958334)\n",
      "INFO flwr 2025-02-18 20:25:20,767 | server_returns_parameters.py:171 | evaluate_round 4: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:20,768 | server_returns_parameters.py:223 | fit_round 5: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:20,769 | 1323382480.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-18 20:25:20,772 | 1323382480.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-18 20:25:20,775 | 1323382480.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-18 20:25:20,779 | 1323382480.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-18 20:25:20,781 | 1323382480.py:21 | cid: 678\n",
      "DEBUG flwr 2025-02-18 20:25:22,505 | server_returns_parameters.py:237 | fit_round 5 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 87.11it/s]\n",
      "INFO flwr 2025-02-18 20:25:23,881 | server_returns_parameters.py:120 | fit progress: (5, 309.5362389087677, {'accuracy': 0.17875}, 19.338327136007138)\n",
      "INFO flwr 2025-02-18 20:25:23,882 | server_returns_parameters.py:171 | evaluate_round 5: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:23,883 | server_returns_parameters.py:223 | fit_round 6: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:23,885 | 1323382480.py:21 | cid: 2399\n",
      "INFO flwr 2025-02-18 20:25:23,888 | 1323382480.py:21 | cid: 1571\n",
      "INFO flwr 2025-02-18 20:25:23,892 | 1323382480.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-18 20:25:23,895 | 1323382480.py:21 | cid: 3175\n",
      "INFO flwr 2025-02-18 20:25:23,898 | 1323382480.py:21 | cid: 2997\n",
      "DEBUG flwr 2025-02-18 20:25:25,501 | server_returns_parameters.py:237 | fit_round 6 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 80.22it/s]\n",
      "INFO flwr 2025-02-18 20:25:26,979 | server_returns_parameters.py:120 | fit progress: (6, 279.4671425819397, {'accuracy': 0.2825}, 22.436400668986607)\n",
      "INFO flwr 2025-02-18 20:25:26,981 | server_returns_parameters.py:171 | evaluate_round 6: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:26,981 | server_returns_parameters.py:223 | fit_round 7: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:26,982 | 1323382480.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-18 20:25:26,985 | 1323382480.py:21 | cid: 2907\n",
      "INFO flwr 2025-02-18 20:25:26,989 | 1323382480.py:21 | cid: 839\n",
      "INFO flwr 2025-02-18 20:25:26,993 | 1323382480.py:21 | cid: 2184\n",
      "INFO flwr 2025-02-18 20:25:26,995 | 1323382480.py:21 | cid: 2688\n",
      "DEBUG flwr 2025-02-18 20:25:28,154 | server_returns_parameters.py:237 | fit_round 7 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:07, 99.06it/s]\n",
      "INFO flwr 2025-02-18 20:25:29,390 | server_returns_parameters.py:120 | fit progress: (7, 258.1836875677109, {'accuracy': 0.335}, 24.846787385002244)\n",
      "INFO flwr 2025-02-18 20:25:29,391 | server_returns_parameters.py:171 | evaluate_round 7: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:29,391 | server_returns_parameters.py:223 | fit_round 8: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:29,393 | 1323382480.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-18 20:25:29,395 | 1323382480.py:21 | cid: 2184\n",
      "INFO flwr 2025-02-18 20:25:29,399 | 1323382480.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-18 20:25:29,401 | 1323382480.py:21 | cid: 2997\n",
      "INFO flwr 2025-02-18 20:25:29,404 | 1323382480.py:21 | cid: 839\n",
      "DEBUG flwr 2025-02-18 20:25:31,510 | server_returns_parameters.py:237 | fit_round 8 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:10, 77.82it/s]\n",
      "INFO flwr 2025-02-18 20:25:33,025 | server_returns_parameters.py:120 | fit progress: (8, 240.96729409694672, {'accuracy': 0.4025}, 28.481986532977317)\n",
      "INFO flwr 2025-02-18 20:25:33,026 | server_returns_parameters.py:171 | evaluate_round 8: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:33,027 | server_returns_parameters.py:223 | fit_round 9: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:33,029 | 1323382480.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-18 20:25:33,031 | 1323382480.py:21 | cid: 1363\n",
      "INFO flwr 2025-02-18 20:25:33,034 | 1323382480.py:21 | cid: 2997\n",
      "INFO flwr 2025-02-18 20:25:33,035 | 1323382480.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-18 20:25:33,042 | 1323382480.py:21 | cid: 1571\n",
      "DEBUG flwr 2025-02-18 20:25:34,289 | server_returns_parameters.py:237 | fit_round 9 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 85.69it/s]\n",
      "INFO flwr 2025-02-18 20:25:35,686 | server_returns_parameters.py:120 | fit progress: (9, 241.0560336112976, {'accuracy': 0.4646875}, 31.142601326981094)\n",
      "INFO flwr 2025-02-18 20:25:35,687 | server_returns_parameters.py:171 | evaluate_round 9: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-18 20:25:35,688 | server_returns_parameters.py:223 | fit_round 10: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-18 20:25:35,689 | 1323382480.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-18 20:25:35,691 | 1323382480.py:21 | cid: 1571\n",
      "INFO flwr 2025-02-18 20:25:35,695 | 1323382480.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-18 20:25:35,699 | 1323382480.py:21 | cid: 678\n",
      "INFO flwr 2025-02-18 20:25:35,702 | 1323382480.py:21 | cid: 2184\n",
      "DEBUG flwr 2025-02-18 20:25:38,078 | server_returns_parameters.py:237 | fit_round 10 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:11, 71.52it/s]\n",
      "INFO flwr 2025-02-18 20:25:39,708 | server_returns_parameters.py:120 | fit progress: (10, 228.34656012058258, {'accuracy': 0.4390625}, 35.16485069098417)\n",
      "INFO flwr 2025-02-18 20:25:39,709 | server_returns_parameters.py:171 | evaluate_round 10: no clients selected, cancel\n",
      "INFO flwr 2025-02-18 20:25:39,709 | server_returns_parameters.py:150 | FL finished in 35.16624441999011\n",
      "INFO flwr 2025-02-18 20:25:39,710 | app.py:250 | app_fit: losses_distributed []\n",
      "INFO flwr 2025-02-18 20:25:39,711 | app.py:251 | app_fit: metrics_distributed_fit {'train_loss': [(1, {'avg': 0.10479235152403514, 'all': [(5, 0.10567335337400437), (4, 0.10332143120467663), (4, 0.10403791628777981), (4, 0.10228895954787731), (4, 0.10841984674334526)]}), (2, {'avg': 0.10348672703618095, 'all': [(5, 0.10319242179393769), (3, 0.10359044869740804), (4, 0.10283678583800793), (5, 0.10333511084318162), (4, 0.10461627878248692)]}), (3, {'avg': 0.10394290244827668, 'all': [(5, 0.10152100622653962), (4, 0.0998137891292572), (4, 0.10002309083938599), (3, 0.09906131525834401), (8, 0.11131164524704218)]}), (4, {'avg': 0.094246556609869, 'all': [(5, 0.09273688793182373), (4, 0.09307049587368965), (3, 0.0931085819999377), (4, 0.0916257593780756), (4, 0.10078398138284683)]}), (5, {'avg': 0.08633804094532262, 'all': [(3, 0.0846603661775589), (5, 0.07588139325380325), (5, 0.0838897705078125), (4, 0.08284361660480499), (6, 0.10026059299707413)]}), (6, {'avg': 0.06797973643988371, 'all': [(4, 0.07320117298513651), (5, 0.05991738960146904), (4, 0.07331110164523125), (3, 0.07039372498790424), (4, 0.06569437682628632)]}), (7, {'avg': 0.06454515513032674, 'all': [(4, 0.07526569068431854), (4, 0.05863484367728233), (4, 0.05931671988219023), (4, 0.07095818128436804), (4, 0.0585503401234746)]}), (8, {'avg': 0.05318311515908975, 'all': [(4, 0.059751410968601704), (8, 0.058731624856591225), (5, 0.03725252225995064), (4, 0.06445435993373394), (5, 0.045964460074901584)]}), (9, {'avg': 0.03712665373459458, 'all': [(5, 0.0312704473733902), (4, 0.03886955510824919), (4, 0.03792448714375496), (4, 0.038608355447649956), (3, 0.04152374900877476)]}), (10, {'avg': 0.03997864587991326, 'all': [(5, 0.03287922777235508), (6, 0.04946271516382694), (8, 0.038676870753988624), (4, 0.02779388800263405), (4, 0.04941512271761894)]})]}\n",
      "INFO flwr 2025-02-18 20:25:39,711 | app.py:252 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2025-02-18 20:25:39,712 | app.py:253 | app_fit: losses_centralized [(0, 413.6843070983887), (1, 364.48796558380127), (2, 342.5152292251587), (3, 343.5453414916992), (4, 347.0549645423889), (5, 309.5362389087677), (6, 279.4671425819397), (7, 258.1836875677109), (8, 240.96729409694672), (9, 241.0560336112976), (10, 228.34656012058258)]\n",
      "INFO flwr 2025-02-18 20:25:39,712 | app.py:254 | app_fit: metrics_centralized {'accuracy': [(0, 0.0065625), (1, 0.074375), (2, 0.079375), (3, 0.071875), (4, 0.078125), (5, 0.17875), (6, 0.2825), (7, 0.335), (8, 0.4025), (9, 0.4646875), (10, 0.4390625)]}\n"
     ]
    }
   ],
   "source": [
    "# Federated configuration dictionary\n",
    "federated_train_config: dict[str, Any] = {\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "\n",
    "num_rounds = 10\n",
    "\n",
    "num_total_clients = 20\n",
    "\n",
    "num_evaluate_clients = 0\n",
    "num_clients_per_round = 5\n",
    "\n",
    "initial_parameters = ndarrays_to_parameters(seed_model_params)\n",
    "parameters_for_each_round, hist = run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
