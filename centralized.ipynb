{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from typing import Any\n",
    "from logging import INFO, DEBUG\n",
    "from collections import defaultdict, OrderedDict\n",
    "from collections.abc import Sequence, Callable\n",
    "import numbers\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from enum import IntEnum\n",
    "import flwr\n",
    "from flwr.server import History, ServerConfig\n",
    "from flwr.server.strategy import FedAvgM as FedAvg, Strategy\n",
    "from flwr.common import log, NDArrays, Scalar, Parameters, ndarrays_to_parameters\n",
    "from flwr.client.client import Client\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from common.client_utils import (\n",
    "    Net,\n",
    "    load_femnist_dataset,\n",
    "    get_network_generator_cnn as get_network_generator,\n",
    "    train_femnist,\n",
    "    test_femnist,\n",
    "    save_history,\n",
    ")\n",
    "\n",
    "\n",
    "# Add new seeds here for easy autocomplete\n",
    "class Seeds(IntEnum):\n",
    "    \"\"\"Seeds for reproducibility.\"\"\"\n",
    "\n",
    "    DEFAULT = 1337\n",
    "\n",
    "\n",
    "np.random.seed(Seeds.DEFAULT)\n",
    "random.seed(Seeds.DEFAULT)\n",
    "torch.manual_seed(Seeds.DEFAULT)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "PathType = Path | str | None\n",
    "\n",
    "\n",
    "def get_device() -> str:\n",
    "    \"\"\"Get the device (cuda, mps, cpu).\"\"\"\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = \"mps\"\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = Path.cwd()\n",
    "dataset_dir: Path = home_dir / \"femnist\"\n",
    "data_dir: Path = dataset_dir / \"data\"\n",
    "centralized_partition: Path = dataset_dir / \"client_data_mappings\" / \"centralized\"\n",
    "centralized_mapping: Path = dataset_dir / \"client_data_mappings\" / \"centralized\" / \"0\"\n",
    "federated_partition: Path = dataset_dir / \"client_data_mappings\" / \"fed_natural\"\n",
    "\n",
    "# Decompress dataset\n",
    "if not dataset_dir.exists():\n",
    "    with tarfile.open(home_dir / \"femnist.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(path=home_dir)\n",
    "    log(INFO, \"Dataset extracted in %s\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_parameters(net: Module, parameters: NDArrays) -> Module:\n",
    "    \"\"\"Put a set of parameters into the model object.\"\"\"\n",
    "    weights = parameters\n",
    "    params_dict = zip(net.state_dict().keys(), weights, strict=False)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(np.copy(v)) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "    return net\n",
    "\n",
    "\n",
    "def get_model_parameters(net: Module) -> NDArrays:\n",
    "    \"\"\"Get the current model parameters as NDArrays.\"\"\"\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_noise_scale_from_gradients(grad_list, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the noise scale (Bsimple) from a list of gradient vectors.\n",
    "    \n",
    "    Parameters:\n",
    "        grad_list (list[Tensor]): List of gradient vectors.\n",
    "        eps (float): Small constant for numerical stability.\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated noise scale.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not grad_list:\n",
    "            log(DEBUG, \"Grad list empty\")\n",
    "            return None\n",
    "\n",
    "        # Stack gradients: shape (num_batches, num_params)\n",
    "        grad_stack = torch.stack(grad_list)\n",
    "        mean_grad = grad_stack.mean(dim=0)\n",
    "        # Compute average variance per parameter element.\n",
    "        var_grad = grad_stack.var(dim=0, unbiased=False).mean()\n",
    "        denom = mean_grad.norm()**2 + eps\n",
    "        noise_scale = var_grad / denom\n",
    "        return noise_scale.item()\n",
    "    except Exception as e:\n",
    "        log(DEBUG, \"Error in compute_noise_scale_from_gradients: %s\", e)\n",
    "        return None\n",
    "\n",
    "def get_gradient_vector(model, data, target, loss_fn, device):\n",
    "    model.zero_grad()\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    grads = []\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grads.append(p.grad.view(-1))\n",
    "    if grads:\n",
    "        return torch.cat(grads)\n",
    "    log(DEBUG, \"No gradients found\")\n",
    "    return None\n",
    "\n",
    "def collect_gradients(model, train_loader, device, criterion, num_mini_batches):\n",
    "    grad_vectors = []\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        if i >= num_mini_batches:\n",
    "            break\n",
    "        grad_vector = get_gradient_vector(model, data, target, criterion, device)\n",
    "        if grad_vector is not None:\n",
    "            grad_vectors.append(grad_vector)\n",
    "    return grad_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerRayClient(flwr.client.NumPyClient):\n",
    "    \"\"\"Flower client for the FEMNIST dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cid: int,\n",
    "        partition_dir: Path,\n",
    "        model_generator: Callable[[], Module],\n",
    "    ) -> None:\n",
    "        \"\"\"Init the client with its unique id and the folder to load data from.\n",
    "\n",
    "        Parameters:\n",
    "            cid (int): Unique client id for a client used to map it to its data\n",
    "                partition\n",
    "            partition_dir (Path): The directory containing data for each\n",
    "                client/client id\n",
    "            model_generator (Callable[[], Module]): The model generator function\n",
    "        \n",
    "        \"\"\"\n",
    "        self.cid = cid\n",
    "        log(INFO, \"cid: %s\", self.cid)\n",
    "        self.partition_dir = partition_dir\n",
    "        self.device = str(\n",
    "            torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        )\n",
    "        self.model_generator: Callable[[], Module] = model_generator\n",
    "        self.properties: dict[str, Scalar] = {\"tensor_type\": \"numpy.ndarray\"}\n",
    "\n",
    "    def set_parameters(self, parameters: NDArrays) -> Module:\n",
    "        \"\"\"Load weights inside the network.\"\"\"\n",
    "        net = self.model_generator()\n",
    "        return set_model_parameters(net, parameters)\n",
    "\n",
    "    def get_parameters(self, config: dict[str, Scalar]) -> NDArrays:\n",
    "        \"\"\"Return weights from a given model.\n",
    "\n",
    "        If no model is passed, then a local model is created.\n",
    "        This can be used to initialise a model in the\n",
    "        server.\n",
    "        The config param is not used but is mandatory in Flower.\n",
    "\n",
    "        \"\"\"\n",
    "        net = self.model_generator()\n",
    "        return get_model_parameters(net)\n",
    "\n",
    "    def fit(self, parameters: NDArrays, config: dict[str, Scalar]) -> tuple[NDArrays, int, dict]:\n",
    "        \"\"\"Receive and train a model on the local client data.\"\"\"\n",
    "        # Only create model right before training/testing\n",
    "        # To lower memory usage when idle\n",
    "        try:\n",
    "            net = self.set_parameters(parameters)\n",
    "            net.to(self.device)\n",
    "\n",
    "\n",
    "            train_loader: DataLoader = self._create_data_loader(config, name=\"train\")\n",
    "            train_loss = self._train(net, train_loader=train_loader, config=config)\n",
    "\n",
    "            # Compute gradients\n",
    "            # Collect gradients for noise scale estimation.\n",
    "            grad_vectors = collect_gradients(net, train_loader, self.device, torch.nn.CrossEntropyLoss(), 5)\n",
    "            # Compute local noise scale (Bsimple) on this client.\n",
    "            local_noise_scale = compute_noise_scale_from_gradients(grad_vectors)\n",
    "            return get_model_parameters(net), len(train_loader), {\"train_loss\": train_loss, \"noise_scale\": local_noise_scale}\n",
    "        except Exception as e:\n",
    "            log(DEBUG, f\"---------------------- A client raised error: {e}: {self.cid}\")\n",
    "\n",
    "    def evaluate(self, parameters: NDArrays, config: dict[str, Scalar]) -> tuple[float, int, dict]:\n",
    "        \"\"\"Receive and test a model on the local client data.\"\"\"\n",
    "        net = self.set_parameters(parameters)\n",
    "        net.to(self.device)\n",
    "\n",
    "        test_loader: DataLoader = self._create_data_loader(config, name=\"test\")\n",
    "        loss, accuracy = self._test(net, test_loader=test_loader, config=config)\n",
    "        return loss, len(test_loader), {\"local_accuracy\": accuracy}\n",
    "\n",
    "    def _create_data_loader(self, config: dict[str, Scalar], name: str) -> DataLoader:\n",
    "        \"\"\"Create the data loader using the specified config parameters.\"\"\"\n",
    "        batch_size = int(config[\"batch_size\"])\n",
    "        num_workers = int(config[\"num_workers\"])\n",
    "        dataset = self._load_dataset(name)\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=(name == \"train\"),\n",
    "        )\n",
    "\n",
    "    def _load_dataset(self, name: str) -> Dataset:\n",
    "        full_file: Path = self.partition_dir / str(self.cid)\n",
    "        return load_femnist_dataset(\n",
    "            mapping=full_file,\n",
    "            name=name,\n",
    "            data_dir=data_dir,\n",
    "        )\n",
    "\n",
    "    def _train(\n",
    "        self, net: Module, train_loader: DataLoader, config: dict[str, Scalar]\n",
    "    ) -> float:\n",
    "        return train_femnist(\n",
    "            net=net,\n",
    "            train_loader=train_loader,\n",
    "            epochs=int(config[\"epochs\"]),\n",
    "            device=self.device,\n",
    "            optimizer=torch.optim.AdamW(\n",
    "                net.parameters(),\n",
    "                lr=float(config[\"client_learning_rate\"]),\n",
    "                weight_decay=float(config[\"weight_decay\"]),\n",
    "            ),\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "            max_batches=int(config[\"max_batches\"]),\n",
    "            cid=self.cid,\n",
    "        )\n",
    "\n",
    "    def _test(\n",
    "        self, net: Module, test_loader: DataLoader, config: dict[str, Scalar]\n",
    "    ) -> tuple[float, float]:\n",
    "        return test_femnist(\n",
    "            net=net,\n",
    "            test_loader=test_loader,\n",
    "            device=self.device,\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "            max_batches=int(config[\"max_batches\"]),\n",
    "        )\n",
    "\n",
    "    def get_properties(self, config: dict[str, Scalar]) -> dict[str, Scalar]:\n",
    "        \"\"\"Return properties for this client.\"\"\"\n",
    "        return self.properties\n",
    "\n",
    "    def get_train_set_size(self) -> int:\n",
    "        \"\"\"Return the client train set size.\"\"\"\n",
    "        return len(self._load_dataset(\"train\"))  # type: ignore[reportArgumentType]\n",
    "\n",
    "    def get_test_set_size(self) -> int:\n",
    "        \"\"\"Return the client test set size.\"\"\"\n",
    "        return len(self._load_dataset(\"test\"))  # type: ignore[reportArgumentType]\n",
    "\n",
    "\n",
    "def fit_client_seeded(\n",
    "    client: FlowerRayClient,\n",
    "    params: NDArrays,\n",
    "    conf: dict[str, Any],\n",
    "    seed: Seeds = Seeds.DEFAULT,\n",
    "    **kwargs: Any,\n",
    ") -> tuple[NDArrays, int, dict]:\n",
    "    \"\"\"Wrap to always seed client training.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    return client.fit(params, conf, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flower_client_generator(\n",
    "    model_generator: Callable[[], Module],\n",
    "    partition_dir: Path,\n",
    "    mapping_fn: Callable[[int], int] | None = None,\n",
    ") -> Callable[[str], FlowerRayClient]:\n",
    "    \"\"\"Wrap the client instance generator.\n",
    "\n",
    "    A mapping function could be used for filtering/ordering clients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model_generator (Callable[[], Module]): model generator function.\n",
    "        partition_dir (Path): directory containing the partition.\n",
    "        mapping_fn (Optional[Callable[[int], int]]): function mapping sorted/filtered\n",
    "            ids to real cid.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> FlowerRayClient:\n",
    "        \"\"\"Create a single client instance given the client id `cid`.\"\"\"\n",
    "        return FlowerRayClient(\n",
    "            cid=mapping_fn(int(cid)) if mapping_fn is not None else int(cid),\n",
    "            partition_dir=partition_dir,\n",
    "            model_generator=model_generator,\n",
    "        )\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_critical_batch(noise_scales: list, constant: float = 1.0) -> float:\n",
    "    # simple avg of noise scales\n",
    "    avg_noise_scale = np.mean(noise_scales)\n",
    "    eps = 1e-8\n",
    "    \n",
    "    # Computing an estimated critical batch size (Bcrit) using a simple heuristic.\n",
    "    critical_batch_size = constant / (avg_noise_scale + eps)\n",
    "    return critical_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralized_experiment(centralized_train_cfg, centralized_test_cfg, train_loader, test_loader, device):\n",
    "    model = network_generator().to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=centralized_train_cfg[\"client_learning_rate\"],\n",
    "        weight_decay=centralized_train_cfg[\"weight_decay\"]\n",
    "        )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    epoch_accuracies = []\n",
    "    epoch_losses = []\n",
    "    epoch_noise_scales = []\n",
    "\n",
    "    for epoch in range(centralized_train_cfg[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if batch_idx >= centralized_train_cfg[\"max_batches\"]:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "        running_loss /= len(train_loader.dataset)\n",
    "        epoch_losses.append(running_loss)\n",
    "\n",
    "        # collect gradients over a few mini-batches\n",
    "        grad_vectors = collect_gradients(model, train_loader, device, criterion, 5) \n",
    "        noise_scale = compute_noise_scale_from_gradients(grad_vectors)\n",
    "        epoch_noise_scales.append(noise_scale)\n",
    "\n",
    "        # Evaluate the trained model\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                if batch_idx >= centralized_test_cfg[\"max_batches\"]:\n",
    "                    break\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                preds = output.argmax(dim=1)\n",
    "                correct += (preds == target).sum().item()\n",
    "                total += target.size(0)\n",
    "        accuracy = correct / total\n",
    "        epoch_accuracies.append(accuracy)\n",
    "\n",
    "        log(INFO, f\"Epoch {epoch+1}/{centralized_train_cfg['epochs']}, Loss: {running_loss:.4f}, \"\n",
    "              f\"Noise scale: {noise_scale:.4e}, Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracies\": epoch_accuracies,\n",
    "        \"losses\": epoch_losses,\n",
    "        \"noise_scales\": epoch_noise_scales,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_generator = get_network_generator()\n",
    "\n",
    "# Load the centralized dataset using the same function as in FL.\n",
    "# The centralized mapping folder should be the one used in your FL centralized experiment.\n",
    "centralized_train_dataset = load_femnist_dataset(data_dir=data_dir, mapping=centralized_mapping, name=\"train\")\n",
    "centralized_test_dataset = load_femnist_dataset(data_dir=data_dir, mapping=centralized_mapping, name=\"test\")\n",
    "\n",
    "# Use the same configuration parameters as in your FL config.\n",
    "centralized_train_config: dict[str, Any] = {\n",
    "    \"epochs\": 1, # we have 5 epochs * 10 rounds in FL\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "centralized_test_config: dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_batch_sizes = [8, 16, 32, 64, 128]\n",
    "\n",
    "centralized_results = []\n",
    "\n",
    "for batch_size in experiment_batch_sizes:\n",
    "\n",
    "    train_cfg = centralized_train_config.copy()\n",
    "    train_cfg[\"batch_size\"] = batch_size\n",
    "\n",
    "    test_cfg = centralized_test_config.copy()\n",
    "    test_cfg[\"batch_size\"] = batch_size\n",
    "\n",
    "    # Create DataLoaders with the same settings.\n",
    "    centralized_train_loader = DataLoader(\n",
    "        dataset=centralized_train_dataset,\n",
    "        batch_size=train_cfg[\"batch_size\"],\n",
    "        shuffle=True,                # Shuffle for training\n",
    "        num_workers=train_cfg[\"num_workers\"],\n",
    "        drop_last=True,              # If FL training drops last batch, do the same here.\n",
    "    )\n",
    "\n",
    "    centralized_test_loader = DataLoader(\n",
    "        dataset=centralized_test_dataset,\n",
    "        batch_size=test_cfg[\"batch_size\"],\n",
    "        shuffle=False,               # No shuffling during evaluation\n",
    "        num_workers=test_cfg[\"num_workers\"],\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    no_fl_results = centralized_experiment(centralized_train_config, centralized_test_config, centralized_train_loader, centralized_test_loader, get_device())\n",
    "\n",
    "    centralized_results.append((batch_size, no_fl_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_batches = []\n",
    "\n",
    "# Create side-by-side subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Left subplot: Accuracy vs Epoch for each batch size configuration\n",
    "for batch_size, results in centralized_results:\n",
    "    axes[0].plot(results[\"accuracies\"], label=f\"Batch size: {batch_size}\")\n",
    "    bcrit = compute_critical_batch(results[\"noise_scales\"], constant=0.01)\n",
    "    critical_batches.append((batch_size, bcrit))\n",
    "    # Logging information (optional)\n",
    "    log(INFO, f\"Batch size: {batch_size}\")\n",
    "    log(INFO, f\"Accuracies: {results['accuracies']}\")\n",
    "    log(INFO, f\"Losses: {results['losses']}\")\n",
    "    log(INFO, f\"Noise scales: {results['noise_scales']}\")\n",
    "    log(INFO, f\"Critical batch size: {bcrit}\")\n",
    "\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].set_title(\"Centralized Training: Accuracy vs Epoch\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Right subplot: Critical Batch Size vs Batch Size\n",
    "batch_sizes = [bs for bs, _ in critical_batches]\n",
    "bcrit_values = [bcrit for _, bcrit in critical_batches]\n",
    "\n",
    "axes[1].plot(batch_sizes, bcrit_values, marker='o')\n",
    "axes[1].set_xlabel(\"Batch Size\")\n",
    "axes[1].set_ylabel(\"Critical Batch Size\")\n",
    "axes[1].set_title(\"Critical Batch Size vs Batch Size\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('centralized_results.json', 'w') as f:\n",
    "    json.dump(centralized_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('centralized_results.json', 'r') as f:\n",
    "    centralized_results = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
