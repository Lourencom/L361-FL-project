{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from logging import INFO, DEBUG\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.signal import medfilt\n",
    "from flwr.common import log, ndarrays_to_parameters\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from src.common.client_utils import (\n",
    "    load_femnist_dataset,\n",
    "    get_network_generator_cnn as get_network_generator,\n",
    "    get_device,\n",
    "    get_model_parameters,\n",
    "    aggregate_weighted_average,\n",
    ")\n",
    "\n",
    "\n",
    "from src.flwr_core import (\n",
    "    set_all_seeds,\n",
    "    get_paths,\n",
    "    decompress_dataset,\n",
    "    get_flower_client_generator,\n",
    "    sample_random_clients,\n",
    "    get_federated_evaluation_function,\n",
    ")\n",
    "\n",
    "from src.estimate import (\n",
    "    compute_critical_batch,\n",
    ")\n",
    "\n",
    "from src.experiments_simulation import (\n",
    "    run_simulation,\n",
    "    centralized_experiment,\n",
    ")\n",
    "\n",
    "from src.utils import get_centralized_acc_from_hist\n",
    "\n",
    "PathType = Path | str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds()\n",
    "\n",
    "PATHS = get_paths()\n",
    "\n",
    "HOME_DIR = PATHS[\"home_dir\"]\n",
    "DATASET_DIR = PATHS[\"dataset_dir\"]\n",
    "DATA_DIR = PATHS[\"data_dir\"]\n",
    "CENTRALIZED_PARTITION = PATHS[\"centralized_partition\"]\n",
    "CENTRALIZED_MAPPING = PATHS[\"centralized_mapping\"]\n",
    "FEDERATED_PARTITION = PATHS[\"federated_partition\"]\n",
    "\n",
    "# extract dataset from tar.gz\n",
    "decompress_dataset(PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_GENERATOR = get_network_generator()\n",
    "SEED_NET = NETWORK_GENERATOR()\n",
    "SEED_MODEL_PARAMS = get_model_parameters(SEED_NET)\n",
    "CID_CLIENT_GENERATOR = get_flower_client_generator(NETWORK_GENERATOR, FEDERATED_PARTITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the centralized dataset using the same function as in FL.\n",
    "# The centralized mapping folder should be the one used in the FL centralized experiment.\n",
    "centralized_train_dataset = load_femnist_dataset(data_dir=DATA_DIR,mapping=CENTRALIZED_MAPPING, name=\"train\")\n",
    "centralized_test_dataset = load_femnist_dataset(data_dir=DATA_DIR, mapping=CENTRALIZED_MAPPING, name=\"test\")\n",
    "\n",
    "centralized_train_config = {\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "centralized_test_config = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "    \"target_accuracy\": 0.60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_experiment_results = []\n",
    "\n",
    "centralized_experiment_batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "for batch_size in centralized_experiment_batch_sizes:\n",
    "\n",
    "    train_cfg = centralized_train_config.copy()\n",
    "    train_cfg[\"batch_size\"] = batch_size\n",
    "    ratio = np.sqrt(batch_size / 256)\n",
    "    train_cfg[\"client_learning_rate\"] = ratio * 0.1\n",
    "\n",
    "    test_cfg = centralized_test_config.copy()\n",
    "    test_cfg[\"batch_size\"] = batch_size\n",
    "\n",
    "    # Create DataLoaders with the same settings.\n",
    "    centralized_train_loader = DataLoader(\n",
    "        dataset=centralized_train_dataset,\n",
    "        batch_size=train_cfg[\"batch_size\"],\n",
    "        shuffle=True,                # Shuffle for training\n",
    "        num_workers=train_cfg[\"num_workers\"],\n",
    "        drop_last=True,              # If FL training drops last batch, do the same here.\n",
    "    )\n",
    "\n",
    "    centralized_test_loader = DataLoader(\n",
    "        dataset=centralized_test_dataset,\n",
    "        batch_size=test_cfg[\"batch_size\"],\n",
    "        shuffle=False,               # No shuffling during evaluation\n",
    "        num_workers=test_cfg[\"num_workers\"],\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    centralized_results = centralized_experiment(centralized_train_config, centralized_test_config, centralized_train_loader, centralized_test_loader, get_device(), NETWORK_GENERATOR())\n",
    "    centralized_experiment_results.append((batch_size, centralized_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(save_file_name):\n",
    "    with open(save_file_name, \"r\") as f:\n",
    "        results_dict = json.load(f)\n",
    "    return results_dict\n",
    "\n",
    "def save_experiment(save_file_name, results_dict):\n",
    "    if os.path.exists(save_file_name):\n",
    "        print(f\"File {save_file_name} already exists\")\n",
    "        return\n",
    "    with open(save_file_name, \"w\") as f:\n",
    "        json.dump(results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size, results in centralized_experiment_results:\n",
    "    save_experiment(f\"centralized_experiment_results_{batch_size}.json\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
