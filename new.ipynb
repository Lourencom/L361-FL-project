{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from typing import Any\n",
    "from logging import INFO\n",
    "from collections import defaultdict, OrderedDict\n",
    "from collections.abc import Sequence, Callable\n",
    "import numbers\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from enum import IntEnum\n",
    "import flwr\n",
    "from flwr.server import History, ServerConfig\n",
    "from flwr.server.strategy import FedAvgM as FedAvg, Strategy\n",
    "from flwr.common import log, NDArrays, Scalar, Parameters, ndarrays_to_parameters\n",
    "from flwr.client.client import Client\n",
    "\n",
    "from common.client_utils import (\n",
    "    Net,\n",
    "    load_femnist_dataset,\n",
    "    get_network_generator_cnn as get_network_generator,\n",
    "    train_femnist,\n",
    "    test_femnist,\n",
    "    save_history,\n",
    ")\n",
    "\n",
    "\n",
    "# Add new seeds here for easy autocomplete\n",
    "class Seeds(IntEnum):\n",
    "    \"\"\"Seeds for reproducibility.\"\"\"\n",
    "\n",
    "    DEFAULT = 1337\n",
    "\n",
    "\n",
    "np.random.seed(Seeds.DEFAULT)\n",
    "random.seed(Seeds.DEFAULT)\n",
    "torch.manual_seed(Seeds.DEFAULT)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "PathType = Path | str | None\n",
    "\n",
    "\n",
    "def get_device() -> str:\n",
    "    \"\"\"Get the device (cuda, mps, cpu).\"\"\"\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = \"mps\"\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = Path.cwd()\n",
    "dataset_dir: Path = home_dir / \"femnist\"\n",
    "data_dir: Path = dataset_dir / \"data\"\n",
    "centralized_partition: Path = dataset_dir / \"client_data_mappings\" / \"centralized\"\n",
    "centralized_mapping: Path = dataset_dir / \"client_data_mappings\" / \"centralized\" / \"0\"\n",
    "federated_partition: Path = dataset_dir / \"client_data_mappings\" / \"fed_natural\"\n",
    "\n",
    "# Decompress dataset\n",
    "if not dataset_dir.exists():\n",
    "    with tarfile.open(home_dir / \"femnist.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(path=home_dir)\n",
    "    log(INFO, \"Dataset extracted in %s\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_parameters(net: Module, parameters: NDArrays) -> Module:\n",
    "    \"\"\"Put a set of parameters into the model object.\"\"\"\n",
    "    weights = parameters\n",
    "    params_dict = zip(net.state_dict().keys(), weights, strict=False)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(np.copy(v)) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "    return net\n",
    "\n",
    "\n",
    "def get_model_parameters(net: Module) -> NDArrays:\n",
    "    \"\"\"Get the current model parameters as NDArrays.\"\"\"\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerRayClient(flwr.client.NumPyClient):\n",
    "    \"\"\"Flower client for the FEMNIST dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cid: int,\n",
    "        partition_dir: Path,\n",
    "        model_generator: Callable[[], Module],\n",
    "    ) -> None:\n",
    "        \"\"\"Init the client with its unique id and the folder to load data from.\n",
    "\n",
    "        Parameters:\n",
    "            cid (int): Unique client id for a client used to map it to its data\n",
    "                partition\n",
    "            partition_dir (Path): The directory containing data for each\n",
    "                client/client id\n",
    "            model_generator (Callable[[], Module]): The model generator function\n",
    "        \n",
    "        \"\"\"\n",
    "        self.cid = cid\n",
    "        log(INFO, \"cid: %s\", self.cid)\n",
    "        self.partition_dir = partition_dir\n",
    "        self.device = str(\n",
    "            torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        )\n",
    "        self.model_generator: Callable[[], Module] = model_generator\n",
    "        self.properties: dict[str, Scalar] = {\"tensor_type\": \"numpy.ndarray\"}\n",
    "\n",
    "    def set_parameters(self, parameters: NDArrays) -> Module:\n",
    "        \"\"\"Load weights inside the network.\"\"\"\n",
    "        net = self.model_generator()\n",
    "        return set_model_parameters(net, parameters)\n",
    "\n",
    "    def get_parameters(self, config: dict[str, Scalar]) -> NDArrays:\n",
    "        \"\"\"Return weights from a given model.\n",
    "\n",
    "        If no model is passed, then a local model is created.\n",
    "        This can be used to initialise a model in the\n",
    "        server.\n",
    "        The config param is not used but is mandatory in Flower.\n",
    "\n",
    "        \"\"\"\n",
    "        net = self.model_generator()\n",
    "        return get_model_parameters(net)\n",
    "\n",
    "    def fit(self, parameters: NDArrays, config: dict[str, Scalar]) -> tuple[NDArrays, int, dict]:\n",
    "        \"\"\"Receive and train a model on the local client data.\"\"\"\n",
    "        # Only create model right before training/testing\n",
    "        # To lower memory usage when idle\n",
    "        net = self.set_parameters(parameters)\n",
    "        net.to(self.device)\n",
    "\n",
    "        train_loader: DataLoader = self._create_data_loader(config, name=\"train\")\n",
    "        train_loss = self._train(net, train_loader=train_loader, config=config)\n",
    "        return get_model_parameters(net), len(train_loader), {\"train_loss\": train_loss}\n",
    "\n",
    "    def evaluate(self, parameters: NDArrays, config: dict[str, Scalar]) -> tuple[float, int, dict]:\n",
    "        \"\"\"Receive and test a model on the local client data.\"\"\"\n",
    "        net = self.set_parameters(parameters)\n",
    "        net.to(self.device)\n",
    "\n",
    "        test_loader: DataLoader = self._create_data_loader(config, name=\"test\")\n",
    "        loss, accuracy = self._test(net, test_loader=test_loader, config=config)\n",
    "        return loss, len(test_loader), {\"local_accuracy\": accuracy}\n",
    "\n",
    "    def _create_data_loader(self, config: dict[str, Scalar], name: str) -> DataLoader:\n",
    "        \"\"\"Create the data loader using the specified config parameters.\"\"\"\n",
    "        batch_size = int(config[\"batch_size\"])\n",
    "        num_workers = int(config[\"num_workers\"])\n",
    "        dataset = self._load_dataset(name)\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=(name == \"train\"),\n",
    "        )\n",
    "\n",
    "    def _load_dataset(self, name: str) -> Dataset:\n",
    "        full_file: Path = self.partition_dir / str(self.cid)\n",
    "        return load_femnist_dataset(\n",
    "            mapping=full_file,\n",
    "            name=name,\n",
    "            data_dir=data_dir,\n",
    "        )\n",
    "\n",
    "    def _train(\n",
    "        self, net: Module, train_loader: DataLoader, config: dict[str, Scalar]\n",
    "    ) -> float:\n",
    "        return train_femnist(\n",
    "            net=net,\n",
    "            train_loader=train_loader,\n",
    "            epochs=int(config[\"epochs\"]),\n",
    "            device=self.device,\n",
    "            optimizer=torch.optim.AdamW(\n",
    "                net.parameters(),\n",
    "                lr=float(config[\"client_learning_rate\"]),\n",
    "                weight_decay=float(config[\"weight_decay\"]),\n",
    "            ),\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "            max_batches=int(config[\"max_batches\"]),\n",
    "        )\n",
    "\n",
    "    def _test(\n",
    "        self, net: Module, test_loader: DataLoader, config: dict[str, Scalar]\n",
    "    ) -> tuple[float, float]:\n",
    "        return test_femnist(\n",
    "            net=net,\n",
    "            test_loader=test_loader,\n",
    "            device=self.device,\n",
    "            criterion=torch.nn.CrossEntropyLoss(),\n",
    "            max_batches=int(config[\"max_batches\"]),\n",
    "        )\n",
    "\n",
    "    def get_properties(self, config: dict[str, Scalar]) -> dict[str, Scalar]:\n",
    "        \"\"\"Return properties for this client.\"\"\"\n",
    "        return self.properties\n",
    "\n",
    "    def get_train_set_size(self) -> int:\n",
    "        \"\"\"Return the client train set size.\"\"\"\n",
    "        return len(self._load_dataset(\"train\"))  # type: ignore[reportArgumentType]\n",
    "\n",
    "    def get_test_set_size(self) -> int:\n",
    "        \"\"\"Return the client test set size.\"\"\"\n",
    "        return len(self._load_dataset(\"test\"))  # type: ignore[reportArgumentType]\n",
    "\n",
    "\n",
    "def fit_client_seeded(\n",
    "    client: FlowerRayClient,\n",
    "    params: NDArrays,\n",
    "    conf: dict[str, Any],\n",
    "    seed: Seeds = Seeds.DEFAULT,\n",
    "    **kwargs: Any,\n",
    ") -> tuple[NDArrays, int, dict]:\n",
    "    \"\"\"Wrap to always seed client training.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    return client.fit(params, conf, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flower_client_generator(\n",
    "    model_generator: Callable[[], Module],\n",
    "    partition_dir: Path,\n",
    "    mapping_fn: Callable[[int], int] | None = None,\n",
    ") -> Callable[[str], FlowerRayClient]:\n",
    "    \"\"\"Wrap the client instance generator.\n",
    "\n",
    "    A mapping function could be used for filtering/ordering clients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        model_generator (Callable[[], Module]): model generator function.\n",
    "        partition_dir (Path): directory containing the partition.\n",
    "        mapping_fn (Optional[Callable[[int], int]]): function mapping sorted/filtered\n",
    "            ids to real cid.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> FlowerRayClient:\n",
    "        \"\"\"Create a single client instance given the client id `cid`.\"\"\"\n",
    "        return FlowerRayClient(\n",
    "            cid=mapping_fn(int(cid)) if mapping_fn is not None else int(cid),\n",
    "            partition_dir=partition_dir,\n",
    "            model_generator=model_generator,\n",
    "        )\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralized Baseline (1 FL client only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-22 11:47:23,876 | 4203729913.py:21 | cid: 0\n"
     ]
    }
   ],
   "source": [
    "network_generator = get_network_generator()\n",
    "seed_net: Net = network_generator()\n",
    "seed_model_params: NDArrays = get_model_parameters(seed_net)\n",
    "\n",
    "centralized_flower_client_generator: Callable[[str], FlowerRayClient] = (\n",
    "    get_flower_client_generator(network_generator, centralized_partition)\n",
    ")\n",
    "centralized_flower_client = centralized_flower_client_generator(str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-22 11:48:58,226 | 2944962118.py:20 | Train Metrics = {'train_loss': 0.07441831767559051}\n"
     ]
    }
   ],
   "source": [
    "centralized_train_config: dict[str, Any] = {\n",
    "    \"epochs\": 4,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "test_config: dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "# Train parameters on the centralised dataset\n",
    "trained_params, num_examples, train_metrics = fit_client_seeded(\n",
    "    centralized_flower_client, params=seed_model_params, conf=centralized_train_config\n",
    ")\n",
    "log(INFO, \"Train Metrics = %s\", train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 100/2329 [00:02<00:55, 39.87it/s]\n",
      "INFO flwr 2025-02-22 11:49:01,374 | 592755603.py:5 | Loss = 217.45845246315002; Test Metrics = {'local_accuracy': 0.3975}\n"
     ]
    }
   ],
   "source": [
    "# Test trained parameters on the centralised dataset\n",
    "loss, num_examples, test_metrics = centralized_flower_client.evaluate(\n",
    "    parameters=trained_params, config=test_config\n",
    ")\n",
    "log(INFO, \"Loss = %s; Test Metrics = %s\", loss, test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated setting with natural partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_clients(\n",
    "    total_clients: int,\n",
    "    filter_less: int,\n",
    "    partition: Path,\n",
    "    seed: int | None = Seeds.DEFAULT,\n",
    ") -> Sequence[int]:\n",
    "    \"\"\"Sample randomly clients.\n",
    "\n",
    "    A filter on the client train set size is performed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        total_clients (int): total number of clients to sample.\n",
    "        filter_less (int): max number of train samples for which the client is\n",
    "            **discarded**.\n",
    "        partition (Path): path to the folder containing the partitioning.\n",
    "    \"\"\"\n",
    "    real_federated_cid_client_generator: Callable[[str], FlowerRayClient] = (\n",
    "        get_flower_client_generator(network_generator, federated_partition)\n",
    "    )\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    list_of_ids = []\n",
    "    while len(list_of_ids) < total_clients:\n",
    "        current_id = random.randint(0, 3229)\n",
    "        if (\n",
    "            real_federated_cid_client_generator(str(current_id)).get_train_set_size()\n",
    "            > filter_less\n",
    "        ):\n",
    "            list_of_ids.append(current_id)\n",
    "    return list_of_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While FEMNIST has more than 3000 clients, we will limit our experiments to 100 (for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-22 11:52:09,027 | 4203729913.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-22 11:52:09,033 | 4203729913.py:21 | cid: 2184\n",
      "INFO flwr 2025-02-22 11:52:09,036 | 4203729913.py:21 | cid: 2907\n",
      "INFO flwr 2025-02-22 11:52:09,039 | 4203729913.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-22 11:52:09,041 | 4203729913.py:21 | cid: 2338\n",
      "INFO flwr 2025-02-22 11:52:09,043 | 4203729913.py:21 | cid: 2399\n",
      "INFO flwr 2025-02-22 11:52:09,046 | 4203729913.py:21 | cid: 2997\n",
      "INFO flwr 2025-02-22 11:52:09,048 | 4203729913.py:21 | cid: 678\n",
      "INFO flwr 2025-02-22 11:52:09,051 | 4203729913.py:21 | cid: 3175\n",
      "INFO flwr 2025-02-22 11:52:09,054 | 4203729913.py:21 | cid: 1363\n",
      "INFO flwr 2025-02-22 11:52:09,056 | 4203729913.py:21 | cid: 1571\n",
      "INFO flwr 2025-02-22 11:52:09,059 | 4203729913.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-22 11:52:09,062 | 4203729913.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-22 11:52:09,064 | 4203729913.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-22 11:52:09,068 | 4203729913.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-22 11:52:09,070 | 4203729913.py:21 | cid: 2855\n",
      "INFO flwr 2025-02-22 11:52:09,073 | 4203729913.py:21 | cid: 839\n",
      "INFO flwr 2025-02-22 11:52:09,075 | 4203729913.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-22 11:52:09,078 | 4203729913.py:21 | cid: 2688\n",
      "INFO flwr 2025-02-22 11:52:09,080 | 4203729913.py:21 | cid: 1494\n",
      "INFO flwr 2025-02-22 11:52:09,083 | 4203729913.py:21 | cid: 447\n",
      "INFO flwr 2025-02-22 11:52:09,088 | 4203729913.py:21 | cid: 1742\n",
      "INFO flwr 2025-02-22 11:52:09,091 | 4203729913.py:21 | cid: 2601\n",
      "INFO flwr 2025-02-22 11:52:09,093 | 4203729913.py:21 | cid: 1633\n",
      "INFO flwr 2025-02-22 11:52:09,096 | 4203729913.py:21 | cid: 267\n",
      "INFO flwr 2025-02-22 11:52:09,100 | 4203729913.py:21 | cid: 2070\n",
      "INFO flwr 2025-02-22 11:52:09,103 | 4203729913.py:21 | cid: 2863\n",
      "INFO flwr 2025-02-22 11:52:09,106 | 4203729913.py:21 | cid: 2736\n",
      "INFO flwr 2025-02-22 11:52:09,109 | 4203729913.py:21 | cid: 1425\n",
      "INFO flwr 2025-02-22 11:52:09,112 | 4203729913.py:21 | cid: 1653\n",
      "INFO flwr 2025-02-22 11:52:09,114 | 4203729913.py:21 | cid: 1652\n",
      "INFO flwr 2025-02-22 11:52:09,117 | 4203729913.py:21 | cid: 3020\n",
      "INFO flwr 2025-02-22 11:52:09,119 | 4203729913.py:21 | cid: 1273\n",
      "INFO flwr 2025-02-22 11:52:09,123 | 4203729913.py:21 | cid: 2718\n",
      "INFO flwr 2025-02-22 11:52:09,125 | 4203729913.py:21 | cid: 73\n",
      "INFO flwr 2025-02-22 11:52:09,129 | 4203729913.py:21 | cid: 1446\n",
      "INFO flwr 2025-02-22 11:52:09,132 | 4203729913.py:21 | cid: 2434\n",
      "INFO flwr 2025-02-22 11:52:09,135 | 4203729913.py:21 | cid: 485\n",
      "INFO flwr 2025-02-22 11:52:09,138 | 4203729913.py:21 | cid: 1887\n",
      "INFO flwr 2025-02-22 11:52:09,140 | 4203729913.py:21 | cid: 1009\n",
      "INFO flwr 2025-02-22 11:52:09,144 | 4203729913.py:21 | cid: 701\n",
      "INFO flwr 2025-02-22 11:52:09,148 | 4203729913.py:21 | cid: 1285\n",
      "INFO flwr 2025-02-22 11:52:09,152 | 4203729913.py:21 | cid: 2782\n",
      "INFO flwr 2025-02-22 11:52:09,154 | 4203729913.py:21 | cid: 2828\n",
      "INFO flwr 2025-02-22 11:52:09,157 | 4203729913.py:21 | cid: 2476\n",
      "INFO flwr 2025-02-22 11:52:09,160 | 4203729913.py:21 | cid: 1872\n",
      "INFO flwr 2025-02-22 11:52:09,162 | 4203729913.py:21 | cid: 2471\n",
      "INFO flwr 2025-02-22 11:52:09,165 | 4203729913.py:21 | cid: 1084\n",
      "INFO flwr 2025-02-22 11:52:09,168 | 4203729913.py:21 | cid: 823\n",
      "INFO flwr 2025-02-22 11:52:09,172 | 4203729913.py:21 | cid: 2243\n",
      "INFO flwr 2025-02-22 11:52:09,174 | 4203729913.py:21 | cid: 275\n",
      "INFO flwr 2025-02-22 11:52:09,177 | 4203729913.py:21 | cid: 2614\n",
      "INFO flwr 2025-02-22 11:52:09,180 | 4203729913.py:21 | cid: 2152\n",
      "INFO flwr 2025-02-22 11:52:09,182 | 4203729913.py:21 | cid: 2534\n",
      "INFO flwr 2025-02-22 11:52:09,185 | 4203729913.py:21 | cid: 2364\n",
      "INFO flwr 2025-02-22 11:52:09,188 | 4203729913.py:21 | cid: 3168\n",
      "INFO flwr 2025-02-22 11:52:09,190 | 4203729913.py:21 | cid: 179\n",
      "INFO flwr 2025-02-22 11:52:09,194 | 4203729913.py:21 | cid: 295\n",
      "INFO flwr 2025-02-22 11:52:09,198 | 4203729913.py:21 | cid: 1668\n",
      "INFO flwr 2025-02-22 11:52:09,200 | 4203729913.py:21 | cid: 2674\n",
      "INFO flwr 2025-02-22 11:52:09,202 | 4203729913.py:21 | cid: 2538\n",
      "INFO flwr 2025-02-22 11:52:09,205 | 4203729913.py:21 | cid: 220\n",
      "INFO flwr 2025-02-22 11:52:09,208 | 4203729913.py:21 | cid: 2767\n",
      "INFO flwr 2025-02-22 11:52:09,211 | 4203729913.py:21 | cid: 70\n",
      "INFO flwr 2025-02-22 11:52:09,214 | 4203729913.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-22 11:52:09,217 | 4203729913.py:21 | cid: 806\n",
      "INFO flwr 2025-02-22 11:52:09,219 | 4203729913.py:21 | cid: 807\n",
      "INFO flwr 2025-02-22 11:52:09,223 | 4203729913.py:21 | cid: 428\n",
      "INFO flwr 2025-02-22 11:52:09,225 | 4203729913.py:21 | cid: 1167\n",
      "INFO flwr 2025-02-22 11:52:09,227 | 4203729913.py:21 | cid: 805\n",
      "INFO flwr 2025-02-22 11:52:09,229 | 4203729913.py:21 | cid: 1852\n",
      "INFO flwr 2025-02-22 11:52:09,231 | 4203729913.py:21 | cid: 3068\n",
      "INFO flwr 2025-02-22 11:52:09,233 | 4203729913.py:21 | cid: 2329\n",
      "INFO flwr 2025-02-22 11:52:09,234 | 4203729913.py:21 | cid: 1287\n",
      "INFO flwr 2025-02-22 11:52:09,237 | 4203729913.py:21 | cid: 51\n",
      "INFO flwr 2025-02-22 11:52:09,240 | 4203729913.py:21 | cid: 2501\n",
      "INFO flwr 2025-02-22 11:52:09,241 | 4203729913.py:21 | cid: 1366\n",
      "INFO flwr 2025-02-22 11:52:09,243 | 4203729913.py:21 | cid: 1770\n",
      "INFO flwr 2025-02-22 11:52:09,244 | 4203729913.py:21 | cid: 2343\n",
      "INFO flwr 2025-02-22 11:52:09,246 | 4203729913.py:21 | cid: 937\n",
      "INFO flwr 2025-02-22 11:52:09,248 | 4203729913.py:21 | cid: 2251\n",
      "INFO flwr 2025-02-22 11:52:09,250 | 4203729913.py:21 | cid: 187\n",
      "INFO flwr 2025-02-22 11:52:09,253 | 4203729913.py:21 | cid: 3178\n",
      "INFO flwr 2025-02-22 11:52:09,255 | 4203729913.py:21 | cid: 2274\n",
      "INFO flwr 2025-02-22 11:52:09,257 | 4203729913.py:21 | cid: 2975\n",
      "INFO flwr 2025-02-22 11:52:09,259 | 4203729913.py:21 | cid: 2645\n",
      "INFO flwr 2025-02-22 11:52:09,260 | 4203729913.py:21 | cid: 1258\n",
      "INFO flwr 2025-02-22 11:52:09,263 | 4203729913.py:21 | cid: 875\n",
      "INFO flwr 2025-02-22 11:52:09,265 | 4203729913.py:21 | cid: 2504\n",
      "INFO flwr 2025-02-22 11:52:09,266 | 4203729913.py:21 | cid: 740\n",
      "INFO flwr 2025-02-22 11:52:09,268 | 4203729913.py:21 | cid: 2167\n",
      "INFO flwr 2025-02-22 11:52:09,270 | 4203729913.py:21 | cid: 2157\n",
      "INFO flwr 2025-02-22 11:52:09,271 | 4203729913.py:21 | cid: 2164\n",
      "INFO flwr 2025-02-22 11:52:09,273 | 4203729913.py:21 | cid: 757\n",
      "INFO flwr 2025-02-22 11:52:09,275 | 4203729913.py:21 | cid: 3175\n",
      "INFO flwr 2025-02-22 11:52:09,277 | 4203729913.py:21 | cid: 2714\n",
      "INFO flwr 2025-02-22 11:52:09,278 | 4203729913.py:21 | cid: 206\n",
      "INFO flwr 2025-02-22 11:52:09,281 | 4203729913.py:21 | cid: 3057\n",
      "INFO flwr 2025-02-22 11:52:09,282 | 4203729913.py:21 | cid: 2026\n",
      "INFO flwr 2025-02-22 11:52:09,284 | 4203729913.py:21 | cid: 2882\n"
     ]
    }
   ],
   "source": [
    "total_clients: int = 100\n",
    "list_of_ids = sample_random_clients(\n",
    "    total_clients, centralized_train_config[\"batch_size\"], federated_partition\n",
    ")\n",
    "\n",
    "federated_client_generator: Callable[[str], FlowerRayClient] = (\n",
    "    get_flower_client_generator(\n",
    "        network_generator, federated_partition, lambda seq_id: list_of_ids[seq_id]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real training FL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_federated_evaluation_function(\n",
    "    batch_size: int,\n",
    "    num_workers: int,\n",
    "    model_generator: Callable[[], Module],\n",
    "    criterion: Module,\n",
    "    max_batches: int,\n",
    ") -> Callable[[int, NDArrays, dict[str, Any]], tuple[float, dict[str, Scalar]]]:\n",
    "    \"\"\"Wrap the external federated evaluation function.\n",
    "\n",
    "    It provides the external federated evaluation function with some\n",
    "    parameters for the dataloader, the model generator function, and\n",
    "    the criterion used in the evaluation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        batch_size (int): batch size of the test set to use.\n",
    "        num_workers (int): correspond to `num_workers` param in the Dataloader object.\n",
    "        model_generator (Callable[[], Module]):  model generator function.\n",
    "        criterion (Module): PyTorch Module containing the criterion for evaluating the\n",
    "        model.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        External federated evaluation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def federated_evaluation_function(\n",
    "        server_round: int,\n",
    "        parameters: NDArrays,\n",
    "        fed_eval_config: dict[\n",
    "            str, Any\n",
    "        ],  # mandatory argument, even if it's not being used\n",
    "    ) -> tuple[float, dict[str, Scalar]]:\n",
    "        \"\"\"Evaluate federated model on the server.\n",
    "\n",
    "        It uses the centralized val set for sake of simplicity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            server_round (int): current federated round.\n",
    "            parameters (NDArrays): current model parameters.\n",
    "            fed_eval_config (dict[str, Any]): mandatory argument in Flower, can contain\n",
    "                some configuration info\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            tuple[float, dict[str, Scalar]]: evaluation results\n",
    "        \"\"\"\n",
    "        device: str = get_device()\n",
    "        net: Module = set_model_parameters(model_generator(), parameters)\n",
    "        net.to(device)\n",
    "\n",
    "        full_file: Path = centralized_mapping\n",
    "        dataset: Dataset = load_femnist_dataset(data_dir, full_file, \"val\")\n",
    "\n",
    "        valid_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        loss, acc = test_femnist(\n",
    "            net=net,\n",
    "            test_loader=valid_loader,\n",
    "            device=device,\n",
    "            criterion=criterion,\n",
    "            max_batches=max_batches,\n",
    "        )\n",
    "        return loss, {\"accuracy\": acc}\n",
    "\n",
    "    return federated_evaluation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_weighted_average(metrics: list[tuple[int, dict]]) -> dict:\n",
    "    \"\"\"Combine results from multiple clients following training or evaluation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        metrics (list[tuple[int, dict]]): collected clients metrics\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        dict: result dictionary containing the aggregate of the metrics passed.\n",
    "    \"\"\"\n",
    "    average_dict: dict = defaultdict(list)\n",
    "    total_examples: int = 0\n",
    "    for num_examples, metrics_dict in metrics:\n",
    "        for key, val in metrics_dict.items():\n",
    "            if isinstance(val, numbers.Number):\n",
    "                average_dict[key].append((num_examples, val))\n",
    "        total_examples += num_examples\n",
    "    return {\n",
    "        key: {\n",
    "            \"avg\": float(\n",
    "                sum([num_examples * metric for num_examples, metric in val])\n",
    "                / float(total_examples)\n",
    "            ),\n",
    "            \"all\": val,\n",
    "        }\n",
    "        for key, val in average_dict.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_seeded_simulation(\n",
    "    client_fn: Callable[[str], Client],\n",
    "    num_clients: int,\n",
    "    config: ServerConfig,\n",
    "    strategy: Strategy,\n",
    "    name: str,\n",
    "    return_all_parameters: bool = False,\n",
    "    seed: int = Seeds.DEFAULT,\n",
    "    iteration: int = 0,\n",
    ") -> tuple[list[tuple[int, NDArrays]], History]:\n",
    "    \"\"\"Wrap to seed client selection.\"\"\"\n",
    "    np.random.seed(seed ^ iteration)\n",
    "    torch.manual_seed(seed ^ iteration)\n",
    "    random.seed(seed ^ iteration)\n",
    "    parameter_list, hist = flwr.simulation.start_simulation_no_ray(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=num_clients,\n",
    "        client_resources={},\n",
    "        config=config,\n",
    "        strategy=strategy,\n",
    "    )\n",
    "    save_history(home_dir, hist, name)\n",
    "    return parameter_list, hist\n",
    "\n",
    "def run_simulation(\n",
    "    num_rounds: int,\n",
    "    num_total_clients: int,\n",
    "    num_clients_per_round: int,\n",
    "    num_evaluate_clients: int,\n",
    "    min_available_clients: int,\n",
    "    min_fit_clients: int,\n",
    "    min_evaluate_clients: int,\n",
    "    evaluate_fn: (Callable[[int, NDArrays, dict[str, Scalar]], tuple[float, dict[str, Scalar]] | None] | None),\n",
    "    on_fit_config_fn: Callable[[int], dict[str, Scalar]],\n",
    "    on_evaluate_config_fn: Callable[[int], dict[str, Scalar]],\n",
    "    initial_parameters: Parameters,\n",
    "    fit_metrics_aggregation_fn: Callable | None,\n",
    "    evaluate_metrics_aggregation_fn: Callable | None,\n",
    "    federated_client_generator: Callable[\n",
    "        [str], flwr.client.NumPyClient\n",
    "    ] = federated_client_generator,\n",
    "    server_learning_rate: float = 1.0,\n",
    "    server_momentum: float = 0.0,\n",
    "    accept_failures: bool = False,\n",
    ") -> tuple[list[tuple[int, NDArrays]], History]:\n",
    "    \"\"\"Run a federated simulation using Flower.\"\"\"\n",
    "    log(INFO, \"FL will execute for %s rounds\", num_rounds)\n",
    "\n",
    "    # Percentage of clients used for train/eval\n",
    "    fraction_fit: float = float(num_clients_per_round) / num_total_clients\n",
    "    fraction_evaluate: float = float(num_evaluate_clients) / num_total_clients\n",
    "\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=fraction_fit,\n",
    "        fraction_evaluate=fraction_evaluate,\n",
    "        min_fit_clients=min_fit_clients,\n",
    "        min_evaluate_clients=min_evaluate_clients,\n",
    "        min_available_clients=min_available_clients,\n",
    "        on_fit_config_fn=on_fit_config_fn,\n",
    "        on_evaluate_config_fn=on_evaluate_config_fn,\n",
    "        evaluate_fn=evaluate_fn,\n",
    "        initial_parameters=initial_parameters,\n",
    "        accept_failures=accept_failures,\n",
    "        fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
    "        evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
    "        server_learning_rate=server_learning_rate,\n",
    "        server_momentum=server_momentum,\n",
    "    )\n",
    "    # resetting the seed for the random selection of clients\n",
    "    # this way the list of clients trained is guaranteed to be always the same\n",
    "\n",
    "    cfg = ServerConfig(num_rounds)\n",
    "\n",
    "    def simulator_client_generator(cid: str) -> Client:\n",
    "        return federated_client_generator(cid).to_client()\n",
    "\n",
    "    parameters_for_each_round, hist = start_seeded_simulation(\n",
    "        client_fn=simulator_client_generator,\n",
    "        num_clients=num_total_clients,\n",
    "        config=cfg,\n",
    "        strategy=strategy,\n",
    "        name=\"fedavg\",\n",
    "        return_all_parameters=True,\n",
    "        seed=Seeds.DEFAULT,\n",
    "    )\n",
    "    return parameters_for_each_round, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FL RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated configuration dictionary\n",
    "federated_train_config = {\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "federated_test_config: dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "num_rounds = 10\n",
    "num_total_clients = 20\n",
    "num_evaluate_clients = 0\n",
    "num_clients_per_round = 5\n",
    "\n",
    "initial_parameters = ndarrays_to_parameters(seed_model_params)\n",
    "\n",
    "federated_evaluation_function = get_federated_evaluation_function(\n",
    "    batch_size=federated_test_config[\"batch_size\"],\n",
    "    num_workers=federated_test_config[\"num_workers\"],\n",
    "    model_generator=network_generator,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    max_batches=federated_test_config[\"max_batches\"],\n",
    ")\n",
    "\n",
    "server_learning_rate = 1.0\n",
    "server_momentum = 0.0\n",
    "accept_failures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-22 12:20:11,808 | 2786322904.py:47 | FL will execute for 10 rounds\n",
      "INFO flwr 2025-02-22 12:20:11,814 | app.py:149 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
      "INFO flwr 2025-02-22 12:20:11,815 | server_returns_parameters.py:81 | Initializing global parameters\n",
      "INFO flwr 2025-02-22 12:20:11,816 | server_returns_parameters.py:273 | Using initial parameters provided by strategy\n",
      "INFO flwr 2025-02-22 12:20:11,819 | server_returns_parameters.py:84 | Evaluating initial parameters\n",
      " 11%|█         | 100/891 [00:03<00:27, 28.68it/s]\n",
      "INFO flwr 2025-02-22 12:20:15,561 | server_returns_parameters.py:87 | initial parameters (loss, other metrics): 413.6843070983887, {'accuracy': 0.0065625}\n",
      "INFO flwr 2025-02-22 12:20:15,562 | server_returns_parameters.py:97 | FL starting\n",
      "DEBUG flwr 2025-02-22 12:20:15,563 | server_returns_parameters.py:223 | fit_round 1: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:15,565 | 4203729913.py:21 | cid: 1494\n",
      "INFO flwr 2025-02-22 12:20:15,566 | 4203729913.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-22 12:20:15,570 | 4203729913.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-22 12:20:15,573 | 4203729913.py:21 | cid: 2399\n",
      "INFO flwr 2025-02-22 12:20:15,575 | 4203729913.py:21 | cid: 1571\n",
      "DEBUG flwr 2025-02-22 12:20:17,028 | server_returns_parameters.py:237 | fit_round 1 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:12, 63.33it/s]\n",
      "INFO flwr 2025-02-22 12:20:18,856 | server_returns_parameters.py:120 | fit progress: (1, 366.4882502555847, {'accuracy': 0.079375}, 3.293076493006083)\n",
      "INFO flwr 2025-02-22 12:20:18,857 | server_returns_parameters.py:171 | evaluate_round 1: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:18,857 | server_returns_parameters.py:223 | fit_round 2: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:18,858 | 4203729913.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-22 12:20:18,861 | 4203729913.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-22 12:20:18,863 | 4203729913.py:21 | cid: 1363\n",
      "INFO flwr 2025-02-22 12:20:18,866 | 4203729913.py:21 | cid: 1494\n",
      "INFO flwr 2025-02-22 12:20:18,868 | 4203729913.py:21 | cid: 2997\n",
      "DEBUG flwr 2025-02-22 12:20:20,334 | server_returns_parameters.py:237 | fit_round 2 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:10, 78.43it/s]\n",
      "INFO flwr 2025-02-22 12:20:21,857 | server_returns_parameters.py:120 | fit progress: (2, 334.25587821006775, {'accuracy': 0.0753125}, 6.294070019008359)\n",
      "INFO flwr 2025-02-22 12:20:21,857 | server_returns_parameters.py:171 | evaluate_round 2: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:21,858 | server_returns_parameters.py:223 | fit_round 3: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:21,859 | 4203729913.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-22 12:20:21,862 | 4203729913.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-22 12:20:21,863 | 4203729913.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-22 12:20:21,866 | 4203729913.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-22 12:20:21,869 | 4203729913.py:21 | cid: 2907\n",
      "DEBUG flwr 2025-02-22 12:20:23,679 | server_returns_parameters.py:237 | fit_round 3 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:10, 77.56it/s]\n",
      "INFO flwr 2025-02-22 12:20:25,214 | server_returns_parameters.py:120 | fit progress: (3, 350.4198303222656, {'accuracy': 0.0765625}, 9.651020490011433)\n",
      "INFO flwr 2025-02-22 12:20:25,215 | server_returns_parameters.py:171 | evaluate_round 3: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:25,216 | server_returns_parameters.py:223 | fit_round 4: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:25,217 | 4203729913.py:21 | cid: 839\n",
      "INFO flwr 2025-02-22 12:20:25,220 | 4203729913.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-22 12:20:25,225 | 4203729913.py:21 | cid: 1473\n",
      "INFO flwr 2025-02-22 12:20:25,230 | 4203729913.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-22 12:20:25,232 | 4203729913.py:21 | cid: 1363\n",
      "DEBUG flwr 2025-02-22 12:20:26,643 | server_returns_parameters.py:237 | fit_round 4 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:08, 88.47it/s]\n",
      "INFO flwr 2025-02-22 12:20:28,019 | server_returns_parameters.py:120 | fit progress: (4, 336.4104588031769, {'accuracy': 0.11875}, 12.456275418007863)\n",
      "INFO flwr 2025-02-22 12:20:28,020 | server_returns_parameters.py:171 | evaluate_round 4: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:28,020 | server_returns_parameters.py:223 | fit_round 5: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:28,021 | 4203729913.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-22 12:20:28,024 | 4203729913.py:21 | cid: 2600\n",
      "INFO flwr 2025-02-22 12:20:28,028 | 4203729913.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-22 12:20:28,030 | 4203729913.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-22 12:20:28,032 | 4203729913.py:21 | cid: 678\n",
      "DEBUG flwr 2025-02-22 12:20:29,787 | server_returns_parameters.py:237 | fit_round 5 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 82.49it/s]\n",
      "INFO flwr 2025-02-22 12:20:31,244 | server_returns_parameters.py:120 | fit progress: (5, 297.8574950695038, {'accuracy': 0.2278125}, 15.680997385003138)\n",
      "INFO flwr 2025-02-22 12:20:31,244 | server_returns_parameters.py:171 | evaluate_round 5: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:31,245 | server_returns_parameters.py:223 | fit_round 6: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:31,246 | 4203729913.py:21 | cid: 2399\n",
      "INFO flwr 2025-02-22 12:20:31,248 | 4203729913.py:21 | cid: 1571\n",
      "INFO flwr 2025-02-22 12:20:31,250 | 4203729913.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-22 12:20:31,253 | 4203729913.py:21 | cid: 3175\n",
      "INFO flwr 2025-02-22 12:20:31,255 | 4203729913.py:21 | cid: 2997\n",
      "DEBUG flwr 2025-02-22 12:20:32,906 | server_returns_parameters.py:237 | fit_round 6 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 81.01it/s]\n",
      "INFO flwr 2025-02-22 12:20:34,385 | server_returns_parameters.py:120 | fit progress: (6, 272.3295862674713, {'accuracy': 0.2953125}, 18.82270324100682)\n",
      "INFO flwr 2025-02-22 12:20:34,386 | server_returns_parameters.py:171 | evaluate_round 6: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:34,387 | server_returns_parameters.py:223 | fit_round 7: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:34,388 | 4203729913.py:21 | cid: 3119\n",
      "INFO flwr 2025-02-22 12:20:34,389 | 4203729913.py:21 | cid: 2907\n",
      "INFO flwr 2025-02-22 12:20:34,391 | 4203729913.py:21 | cid: 839\n",
      "INFO flwr 2025-02-22 12:20:34,396 | 4203729913.py:21 | cid: 2184\n",
      "INFO flwr 2025-02-22 12:20:34,398 | 4203729913.py:21 | cid: 2688\n",
      "DEBUG flwr 2025-02-22 12:20:36,029 | server_returns_parameters.py:237 | fit_round 7 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:10, 77.81it/s]\n",
      "INFO flwr 2025-02-22 12:20:37,561 | server_returns_parameters.py:120 | fit progress: (7, 257.1388862133026, {'accuracy': 0.353125}, 21.997897870998713)\n",
      "INFO flwr 2025-02-22 12:20:37,561 | server_returns_parameters.py:171 | evaluate_round 7: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:37,563 | server_returns_parameters.py:223 | fit_round 8: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:37,564 | 4203729913.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-22 12:20:37,567 | 4203729913.py:21 | cid: 2184\n",
      "INFO flwr 2025-02-22 12:20:37,573 | 4203729913.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-22 12:20:37,578 | 4203729913.py:21 | cid: 2997\n",
      "INFO flwr 2025-02-22 12:20:37,585 | 4203729913.py:21 | cid: 839\n",
      "DEBUG flwr 2025-02-22 12:20:39,543 | server_returns_parameters.py:237 | fit_round 8 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 82.70it/s]\n",
      "INFO flwr 2025-02-22 12:20:41,002 | server_returns_parameters.py:120 | fit progress: (8, 233.2575410604477, {'accuracy': 0.439375}, 25.43931628500286)\n",
      "INFO flwr 2025-02-22 12:20:41,003 | server_returns_parameters.py:171 | evaluate_round 8: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:41,003 | server_returns_parameters.py:223 | fit_round 9: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:41,004 | 4203729913.py:21 | cid: 1498\n",
      "INFO flwr 2025-02-22 12:20:41,007 | 4203729913.py:21 | cid: 1363\n",
      "INFO flwr 2025-02-22 12:20:41,011 | 4203729913.py:21 | cid: 2997\n",
      "INFO flwr 2025-02-22 12:20:41,016 | 4203729913.py:21 | cid: 1603\n",
      "INFO flwr 2025-02-22 12:20:41,018 | 4203729913.py:21 | cid: 1571\n",
      "DEBUG flwr 2025-02-22 12:20:42,522 | server_returns_parameters.py:237 | fit_round 9 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 81.25it/s]\n",
      "INFO flwr 2025-02-22 12:20:44,001 | server_returns_parameters.py:120 | fit progress: (9, 228.5061976313591, {'accuracy': 0.4809375}, 28.438162710008328)\n",
      "INFO flwr 2025-02-22 12:20:44,002 | server_returns_parameters.py:171 | evaluate_round 9: no clients selected, cancel\n",
      "DEBUG flwr 2025-02-22 12:20:44,003 | server_returns_parameters.py:223 | fit_round 10: strategy sampled 5 clients (out of 20)\n",
      "INFO flwr 2025-02-22 12:20:44,004 | 4203729913.py:21 | cid: 2530\n",
      "INFO flwr 2025-02-22 12:20:44,007 | 4203729913.py:21 | cid: 1571\n",
      "INFO flwr 2025-02-22 12:20:44,009 | 4203729913.py:21 | cid: 1260\n",
      "INFO flwr 2025-02-22 12:20:44,014 | 4203729913.py:21 | cid: 678\n",
      "INFO flwr 2025-02-22 12:20:44,019 | 4203729913.py:21 | cid: 2184\n",
      "DEBUG flwr 2025-02-22 12:20:46,289 | server_returns_parameters.py:237 | fit_round 10 received 5 results and 0 failures\n",
      " 11%|█         | 100/891 [00:01<00:09, 81.98it/s]\n",
      "INFO flwr 2025-02-22 12:20:47,756 | server_returns_parameters.py:120 | fit progress: (10, 220.96136194467545, {'accuracy': 0.4925}, 32.1929147990013)\n",
      "INFO flwr 2025-02-22 12:20:47,756 | server_returns_parameters.py:171 | evaluate_round 10: no clients selected, cancel\n",
      "INFO flwr 2025-02-22 12:20:47,757 | server_returns_parameters.py:150 | FL finished in 32.194147023008554\n",
      "INFO flwr 2025-02-22 12:20:47,757 | app.py:250 | app_fit: losses_distributed []\n",
      "INFO flwr 2025-02-22 12:20:47,758 | app.py:251 | app_fit: metrics_distributed_fit {'train_loss': [(1, {'avg': 0.1033182360586666, 'all': [(4, 0.10144311562180519), (4, 0.09971328638494015), (5, 0.10354349315166474), (4, 0.10542896203696728), (4, 0.10640600882470608)]}), (2, {'avg': 0.099534986274583, 'all': [(5, 0.10032255947589874), (5, 0.09831595271825791), (3, 0.0992695540189743), (4, 0.0992464292794466), (4, 0.1005619429051876)]}), (3, {'avg': 0.10074356819192569, 'all': [(4, 0.08976195007562637), (8, 0.11485746875405312), (3, 0.09337010482947032), (4, 0.10008736327290535), (5, 0.09189566373825073)]}), (4, {'avg': 0.08817057311534882, 'all': [(4, 0.08263839036226273), (3, 0.09584120909372966), (5, 0.08276048749685287), (4, 0.09469244629144669), (4, 0.08819051273167133)]}), (5, {'avg': 0.07718174758812656, 'all': [(6, 0.0956869808336099), (5, 0.06844128519296647), (3, 0.08206643909215927), (4, 0.07218398712575436), (5, 0.06478332355618477)]}), (6, {'avg': 0.06397569347172975, 'all': [(3, 0.06501955911517143), (4, 0.06761695723980665), (4, 0.07216627523303032), (5, 0.054360012710094455), (4, 0.06338054966181517)]}), (7, {'avg': 0.06098110750317574, 'all': [(4, 0.059226568788290024), (4, 0.057121945545077324), (4, 0.07018129713833332), (4, 0.06446767970919609), (4, 0.05390804633498192)]}), (8, {'avg': 0.051017947566623874, 'all': [(8, 0.059076075442135334), (4, 0.0540168359875679), (5, 0.03739525713026524), (5, 0.04217820763587952), (4, 0.05998084135353565)]}), (9, {'avg': 0.03574806666001677, 'all': [(4, 0.03363638976588845), (4, 0.039490658324211836), (5, 0.026267724111676216), (4, 0.04035639110952616), (3, 0.043229651947816215)]}), (10, {'avg': 0.040422062286072306, 'all': [(6, 0.05074342029790083), (8, 0.036726785358041525), (4, 0.049057736061513424), (5, 0.035139094293117526), (4, 0.030298615340143442)]})]}\n",
      "INFO flwr 2025-02-22 12:20:47,759 | app.py:252 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2025-02-22 12:20:47,759 | app.py:253 | app_fit: losses_centralized [(0, 413.6843070983887), (1, 366.4882502555847), (2, 334.25587821006775), (3, 350.4198303222656), (4, 336.4104588031769), (5, 297.8574950695038), (6, 272.3295862674713), (7, 257.1388862133026), (8, 233.2575410604477), (9, 228.5061976313591), (10, 220.96136194467545)]\n",
      "INFO flwr 2025-02-22 12:20:47,760 | app.py:254 | app_fit: metrics_centralized {'accuracy': [(0, 0.0065625), (1, 0.079375), (2, 0.0753125), (3, 0.0765625), (4, 0.11875), (5, 0.2278125), (6, 0.2953125), (7, 0.353125), (8, 0.439375), (9, 0.4809375), (10, 0.4925)]}\n"
     ]
    }
   ],
   "source": [
    "parameters_for_each_round, hist = run_simulation(\n",
    "    num_rounds = num_rounds,\n",
    "    num_total_clients = num_total_clients,\n",
    "    num_clients_per_round = num_clients_per_round,\n",
    "    num_evaluate_clients = num_evaluate_clients,\n",
    "    min_available_clients = num_total_clients,\n",
    "    min_fit_clients = num_clients_per_round,\n",
    "    min_evaluate_clients = num_evaluate_clients,\n",
    "    evaluate_fn = federated_evaluation_function,\n",
    "    on_fit_config_fn = lambda _: federated_train_config,\n",
    "    on_evaluate_config_fn = lambda _: federated_test_config,\n",
    "    initial_parameters = initial_parameters,\n",
    "    fit_metrics_aggregation_fn = aggregate_weighted_average,\n",
    "    evaluate_metrics_aggregation_fn = aggregate_weighted_average,\n",
    "    federated_client_generator = federated_client_generator,\n",
    "    server_learning_rate=server_learning_rate,\n",
    "    server_momentum=server_momentum,\n",
    "    accept_failures=accept_failures,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Centralized Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2025-02-22 12:22:15,099 | 4203729913.py:21 | cid: 0\n",
      "INFO flwr 2025-02-22 12:22:26,621 | 1928939441.py:29 | Train Metrics = {'train_loss': 0.06674688722938299}\n",
      "  4%|▍         | 100/2329 [00:01<00:39, 55.96it/s]\n",
      "INFO flwr 2025-02-22 12:22:28,785 | 1928939441.py:35 | Loss = 187.95686101913452; Test Metrics = {'local_accuracy': 0.466875}\n"
     ]
    }
   ],
   "source": [
    "network_generator = get_network_generator()\n",
    "seed_net: Net = network_generator()\n",
    "seed_model_params: NDArrays = get_model_parameters(seed_net)\n",
    "\n",
    "centralized_flower_client_generator: Callable[[str], FlowerRayClient] = (\n",
    "    get_flower_client_generator(network_generator, centralized_partition)\n",
    ")\n",
    "centralized_flower_client = centralized_flower_client_generator(str(0))\n",
    "\n",
    "centralized_train_config: dict[str, Any] = {\n",
    "    \"epochs\": 50, # we have 5 epochs * 10 rounds in FL\n",
    "    \"batch_size\": 32,\n",
    "    \"client_learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "test_config: dict[str, Any] = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 0,\n",
    "    \"max_batches\": 100,\n",
    "}\n",
    "\n",
    "# Train parameters on the centralised dataset\n",
    "trained_params, num_examples, train_metrics = fit_client_seeded(\n",
    "    centralized_flower_client, params=seed_model_params, conf=centralized_train_config\n",
    ")\n",
    "log(INFO, \"Train Metrics = %s\", train_metrics)\n",
    "\n",
    "# Test trained parameters on the centralised dataset\n",
    "loss, num_examples, test_metrics = centralized_flower_client.evaluate(\n",
    "    parameters=trained_params, config=test_config\n",
    ")\n",
    "log(INFO, \"Loss = %s; Test Metrics = %s\", loss, test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
